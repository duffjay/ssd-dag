{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect (with the) Model\n",
    "## Step 1 - run the TFLite model locally\n",
    "\n",
    "In this notebook, we are replicating  some of the original MobileNet TensorFlow Lite functionality.  That means taking the TensorFlow model (checkpoint) and converting it to a TensorFlow Lite model.   This is not quite what the SageMaker tutorial does.   The tutorial sticks with TensorFlow.   Confirm that the Lite model works first - because that is a known path then:\n",
    "- Detect Step 2 - run endpoint as a TensorFlow model\n",
    "- Detect Step 3 - run endpoint as a TensorFlow Lite Model -- the advantage of a Lite model is less latency, faster, less resources -- with slightly less accuracy.    Lite models are the path towards IoT deployments and TPU compatible models\n",
    "\n",
    "We are testing the model before we deploy it as an endpoint.   This is optional but definitely makes sense as we learn this process\n",
    "\n",
    "Your Python environment will require:\n",
    "- tensorflow\n",
    "- opencv\n",
    "- if you are displaying (on a local machine - not SageMaker) - you need gtk2*x86_64\n",
    "\n",
    "####  Installing OpenCV 4.1.2\n",
    "`conda activate <your environment>`  \n",
    "`pip install opencv-python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Environment Variables\n",
    "\n",
    "We are using objects and scripts in the project as much as possible.   They require environment variables to pass along where stuff is stored\n",
    "\n",
    "### Note \n",
    "This notebook assumes output_tflite_graph.tflite is already on the SageMaker server (it will be if you ran the Train Step 3 notebook.)  If not, you can get it from a SageMaker Training Job /output/tflite_model on S3\n",
    "\n",
    "### Execute the Common Globals + 1 other cell that corresponds to the model you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMON\n",
    "PROJECT_DIR = os.getcwd()\n",
    "IMAGE_DIR = os.path.join(PROJECT_DIR, \"data/new_jpeg_images\")\n",
    "ANNOTATION_DIR = os.path.join(PROJECT_DIR, \"data/unverified_annotations\")\n",
    "\n",
    "# if you are running this on a remote server witout GTK, use 'None'\n",
    "# if local with GTK, use 'gtk'\n",
    "# DISPLAY = \"None\"\n",
    "DISPLAY = 'gtk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute 1 of the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNet - V1 - SSD - cfa_prod (Chick-fil-A products)\n",
    "MODEL_NAME = 'tf_lite'   # not using the edge_tpu \n",
    "MODEL_PATH = os.path.join(PROJECT_DIR, \"tflite_model/output_tflite_graph.tflite\")\n",
    "LABEL_MAP = os.path.join(PROJECT_DIR, \"code/cfa_prod_label_map.pbtxt\")\n",
    "\n",
    "# SOURCE images \n",
    "S3_TEST_IMAGES = \"s3://cfa-eadatasciencesb-sagemaker/datasets/cfa_products/test_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNet - V1 - SSD - coco (original)\n",
    "# - this is the original model, it was downloaded to code/ckpt in TrainModel_Step1_Local.ipynb\n",
    "# - convert using UnderstandingTendorRT_ConvertGraph - so now the name is the same\n",
    "MODEL_NAME = 'tf_lite'   # not using the edge_tpu \n",
    "MODEL_PATH = os.path.join(PROJECT_DIR, \"tflite_model/output_tflite_graph.tflite\")\n",
    "LABEL_MAP = os.path.join(PROJECT_DIR, \"code/ckpt/mscoco_label_map.pbtxt\")\n",
    "\n",
    "# SOURCE images \n",
    "S3_TEST_IMAGES = \"s3://cfa-eadatasciencesb-sagemaker/datasets/coco/test_images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Copy the test images locally\n",
    "\n",
    "### aws2\n",
    "- if local, remember to update our credentials\n",
    "- if using AWS CLI Version2,   \n",
    "https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2-linux-mac.html#cliv2-linux-mac-install  \n",
    "- remember, it's:  \n",
    "`aws2 s3 cp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the existing images\n",
    "# - obviously, you can skip this cell if you don't want to delete\n",
    "! rm -rf {IMAGE_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://cfa-eadatasciencesb-sagemaker/datasets/coco/test_images/111-1122_IMG.JPG to data/new_jpeg_images/111-1122_IMG.JPG\n",
      "download: s3://cfa-eadatasciencesb-sagemaker/datasets/coco/test_images/111-1152_IMG.JPG to data/new_jpeg_images/111-1152_IMG.JPG\n",
      "download: s3://cfa-eadatasciencesb-sagemaker/datasets/coco/test_images/Sailing_02.jpg to data/new_jpeg_images/Sailing_02.jpg\n",
      "download: s3://cfa-eadatasciencesb-sagemaker/datasets/coco/test_images/WV 200713.jpg to data/new_jpeg_images/WV 200713.jpg\n",
      "download: s3://cfa-eadatasciencesb-sagemaker/datasets/coco/test_images/WV 200727.jpg to data/new_jpeg_images/WV 200727.jpg\n"
     ]
    }
   ],
   "source": [
    "# version 2\n",
    "! aws s3 cp {S3_TEST_IMAGES} {IMAGE_DIR} --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect\n",
    "The detect.py script will read a directory of images, infer and generate XML (unverified) Annotations (VOC PASCAL schema).    Unverified means if you run them through a labeling program like labelImg, they do not have the verified attribute.    (Downstream, they will be ignored if you try to fold them into training data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jayson/anaconda3/envs/tf114/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n",
      "/home/jayson/anaconda3/envs/tf114/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n",
      "/home/jayson/anaconda3/envs/tf114/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n",
      "/home/jayson/anaconda3/envs/tf114/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n",
      "/home/jayson/anaconda3/envs/tf114/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n",
      "/home/jayson/anaconda3/envs/tf114/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n",
      " 06:04:49  - detector - INFO - Arguments. image_dir: /home/jayson/projects/ssd-dag/data/new_jpeg_images\r\n",
      " 06:04:49  - detector - INFO - Arguments. model_name: tf_lite\r\n",
      " 06:04:49  - detector - INFO - Arguments. model_path: /home/jayson/projects/ssd-dag/tflite_model/output_tflite_graph.tflite\r\n",
      " 06:04:49  - detector - INFO - Arguments. label_map_path: /home/jayson/projects/ssd-dag/code/ckpt/mscoco_label_map.pbtxt\r\n",
      " 06:04:49  - detector - INFO - Arguments. display: gtk\r\n",
      " 06:04:49  - detector - INFO - Arguments. annotation_dir: /home/jayson/projects/ssd-dag/data/unverified_annotations\r\n",
      "WARNING:tensorflow:From /home/jayson/projects/ssd-dag/code/utils/label_map_util.py:119: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\r\n",
      "\r\n",
      " 06:04:49  - tensorflow - WARNING - From /home/jayson/projects/ssd-dag/code/utils/label_map_util.py:119: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"code/detect.py\", line 118, in <module>\r\n",
      "    label_dict = get_label_map_dict(args.label_map_path, 'id')\r\n",
      "  File \"/home/jayson/projects/ssd-dag/code/utils/label_map_util.py\", line 141, in get_label_map_dict\r\n",
      "    label_map = load_labelmap(label_map_path)\r\n",
      "  File \"/home/jayson/projects/ssd-dag/code/utils/label_map_util.py\", line 120, in load_labelmap\r\n",
      "    label_map_string = fid.read()\r\n",
      "  File \"/home/jayson/anaconda3/envs/tf114/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\", line 122, in read\r\n",
      "    self._preread_check()\r\n",
      "  File \"/home/jayson/anaconda3/envs/tf114/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\", line 84, in _preread_check\r\n",
      "    compat.as_bytes(self.__name), 1024 * 512)\r\n",
      "tensorflow.python.framework.errors_impl.NotFoundError: /home/jayson/projects/ssd-dag/code/ckpt/mscoco_label_map.pbtxt; No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! python code/detect.py --image_dir {IMAGE_DIR} --model_name {MODEL_NAME} --model_path {MODEL_PATH} --label_map_path {LABEL_MAP} --display {DISPLAY} --annotation_dir {ANNOTATION_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tarball the annotations\n",
    "os.chdir(\"data\")\n",
    "! tar -czvf  unverif_annotations.tar.gz unverified_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "If you want the annotations - you'll find the annotations tarball in data/ directory\n",
    "use the Notebook browser to download it\n",
    "\n",
    "The fastest, easiest way to review (and correct / verify) is to use labelImg program which will merge the image and annotation\n",
    "\n",
    "The main conclusion here is our model works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf114)",
   "language": "python",
   "name": "tf114"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
