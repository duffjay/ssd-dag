{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Images Using Tensorflow 2.0 (beta)\n",
    "\n",
    "https://www.tensorflow.org/beta/tutorials/load_data/images  \n",
    "https://www.tensorflow.org/tutorials/load_data/tf_records\n",
    "\n",
    "You will need these skills!  What is an image, tf.Example, serialized example etc.  \n",
    "You won't get far with served models without this understanding.\n",
    "\n",
    "## TensorFlow 2.0 Beta\n",
    "\n",
    "### Do this first, then UnderstandingExample.ipynb\n",
    "This code  wants TF 2.0.   But, you can do the Example code with 1.14 (and eager execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib\n",
    "import random\n",
    "import IPython.display as display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!pip install -q tensorflow==2.0.0-beta1\n",
    "# you'll get a tensorflow-serving-api error\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# cfa code utilities\n",
    "from code.cfa_utils.tar_util import extract_tarball_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you really need TensorFlow 2.0.x\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are using tf 1.14, you need to turn on eager execution - but you should be on 2.0\n",
    "# adding it here mainly for reference, you can do most of the tf.Example tutorial in 1.14\n",
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals\n",
    "\n",
    "you can get some test images from S3 - look for cfa_products / test_images  \n",
    "There is also a test.tfrecord (that was created as a slice of the train/val split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.getcwd()\n",
    "\n",
    "S3_ALL_IMAGES = \"s3://cfaanalyticsresearch-sagemaker/datasets/cfa_products/all_images/\"\n",
    "S3_ALL_ANNOTATIONS = \"s3://cfaanalyticsresearch-sagemaker/datasets/cfa_products/all_annotations\"\n",
    "S3_TEST_IMAGES = \"s3://cfaanalyticsresearch-sagemaker/datasets/cfa_products/test_images\"\n",
    "\n",
    "TARBALL_DIR = os.path.join(PROJECT_DIR, \"data/tarballs\")\n",
    "TARBALL_EXTRACT = os.path.join(PROJECT_DIR, \"data/tarball_extract\")\n",
    "\n",
    "IMAGE_DIR = os.path.join(PROJECT_DIR, \"data/jpeg_images\")\n",
    "ANNOTATION_DIR = os.path.join(PROJECT_DIR, \"data/annotations\")\n",
    "\n",
    "MODEL_PATH = os.path.join(PROJECT_DIR, \"trained_model/export/Servo/1564778509\")\n",
    "LABEL_MAP = os.path.join(PROJECT_DIR, \"code/cfa_prod_label_map.pbtxt\")\n",
    "\n",
    "# you can get data using the TrainModel_Step1_Local notebook\n",
    "TEST_TFRECORDS_PATH =  os.path.join(PROJECT_DIR, \"code/tfrecords/test/\")\n",
    "                                    \n",
    "SAMPLE_IMAGE = os.path.join(PROJECT_DIR, \"data/new_jpeg_images/20190710_variety_1562781002.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data - choice\n",
    "### Large Set of Training Data\n",
    "### Test Images\n",
    "\n",
    "Don't do both - choose a set of data then go that block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute THIS block for TRAINING DATA\n",
    "\n",
    "# TRAINING DATA - ALL IMAGES\n",
    "# - delete tarballs first\n",
    "# - delete images first - you can comment this out if you don't like it\n",
    "! rm {TARBALL_DIR}/*.tar.gz -rf\n",
    "! rm {IMAGE_DIR}/*.jpg -rf\n",
    "! rm {ANNOTATION_DIR}/*.xml -rf\n",
    "\n",
    "# get from \n",
    "! aws s3 cp {S3_ALL_IMAGES} {TARBALL_DIR} --recursive --quiet\n",
    "\n",
    "jpg_ext = '.jpg'\n",
    "extract_tarball_directory(TARBALL_DIR, TARBALL_EXTRACT, jpg_ext, IMAGE_DIR)\n",
    "\n",
    "# TRAINING DATA - ALL ANNOTATIONS\n",
    "# - delete tarballs first\n",
    "# - delete annotations first - you can comment this out if you don't like it\n",
    "! rm {TARBALL_DIR}/*.tar.gz -rf\n",
    "! rm {ANNOTATIONS_DIR}/*.xml -rf\n",
    "\n",
    "# get from \n",
    "! aws s3 cp {S3_ALL_ANNOTATIONS} {TARBALL_DIR} --recursive --quiet\n",
    "\n",
    "xml_ext = '.xml'\n",
    "extract_tarball_directory(TARBALL_DIR, TARBALL_EXTRACT, xml_ext, ANNOTATION_DIR)\n",
    "\n",
    "# clean up\n",
    "! rm {TARBALL_DIR}/*.tar.gz -rf\n",
    "! ls {IMAGE_DIR} | wc\n",
    "! ls {ANNOTATION_DIR} | wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excecute THIS block for Test\n",
    "! rm {IMAGE_DIR}/*.jpg -rf\n",
    "! rm {ANNOTATIONS_DIR}/*.xml -rf\n",
    "\n",
    "# test images are not tarballed\n",
    "# get from S3\n",
    "! aws s3 cp {S3_TEST_IMAGES} {IMAGE_DIR} --recursive --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = pathlib.Path(IMAGE_DIR)\n",
    "\n",
    "# opmit .gitkeep here with a glob\n",
    "all_image_paths = list(data_root.glob('*.jpg'))\n",
    "all_image_paths = [str(path) for path in all_image_paths]\n",
    "\n",
    "# randomize the order\n",
    "random.shuffle(all_image_paths)\n",
    "\n",
    "image_count = len(all_image_paths)\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(3):\n",
    "  image_path = random.choice(all_image_paths)\n",
    "  display.display(display.Image(image_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Utilities\n",
    "the tutorial sez:  \n",
    "##### TensorFlow includes all the tools you need to load and process images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an image\n",
    "\n",
    "img_path = all_image_paths[0]\n",
    "print (\"img_path:\", img_path)\n",
    "display.display(display.Image(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the image into a tensor\n",
    "# - note - numpy array but it is a serialized string\n",
    "\n",
    "img_raw = tf.io.read_file(img_path)\n",
    "print (\"img_raw type:\", type(img_raw))\n",
    "print(repr(img_raw)[:100]+\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the tensor (numpy)\n",
    "# - note that an EagerTensor - the value can be printed\n",
    "# - with Eager Execution, you don't have to run the session to get the value\n",
    "img_tensor = tf.image.decode_image(img_raw)\n",
    "print (type(img_tensor), img_tensor)\n",
    "print(img_tensor.shape)\n",
    "print(img_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# operations on the tensor\n",
    "img_final = tf.image.resize(img_tensor, [300, 300])\n",
    "\n",
    "# you can normalize the image\n",
    "img_final = img_final/255.0\n",
    "print(\"tensor shape:\", img_final.shape)\n",
    "print(\"tensor range in values:\", img_final.numpy().min(), img_final.numpy().max())\n",
    "print(\"tensor data type:\", img_final.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.resize(image, [192, 192])\n",
    "  image /= 255.0  # normalize to [0,1] range\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "  image = tf.io.read_file(path)\n",
    "  return preprocess_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test our functions\n",
    "\n",
    "image_path = all_image_paths[0]\n",
    "\n",
    "plt.imshow(load_and_preprocess_image(img_path))\n",
    "plt.grid(False)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the array of strings -- image paths\n",
    "# and make a dataset\n",
    "image_path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
    "print (\"image path dataset type:\", type(image_path_ds))\n",
    "\n",
    "#note - strings, no size\n",
    "print (\"image path dataset:\", image_path_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using dataset map()\n",
    "# you can map the dataset - super cool!\n",
    "# - use the functons we defined earlier\n",
    "# - looks like it will parallelize automatically!\n",
    "\n",
    "image_ds = image_path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "print (\"image dataset type:\", type(image_path_ds))  # same type\n",
    "print (\"image dataset:\", image_path_ds)             # serialized numpy array of the normalized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can pull the value out by iterating on the Dataset\n",
    "\n",
    "for n, image in enumerate(image_ds.take(4)):\n",
    "  plt.figure(figsize=(8,8))\n",
    "  plt.subplot(2,2,n+1)\n",
    "  plt.imshow(image)\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
