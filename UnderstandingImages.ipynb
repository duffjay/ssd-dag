{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Images Using Tensorflow 2.0 (beta)\n",
    "\n",
    "https://www.tensorflow.org/beta/tutorials/load_data/images  \n",
    "https://www.tensorflow.org/tutorials/load_data/tf_records\n",
    "\n",
    "You will need these skills!  What is an image, tf.Example, serialized example etc.  \n",
    "You won't get far with served models without this understanding.\n",
    "\n",
    "## TensorFlow 2.0 Beta\n",
    "\n",
    "### Go through UnderstandingTF_IO FIRST\n",
    "\n",
    "### Do this Second, then UnderstandingExample.ipynb\n",
    "This code  wants TF 2.0.   But, you can do the Example code with 1.14 (and eager execution)\n",
    "\n",
    "### Then, go through UnderstandingImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib\n",
    "import random\n",
    "import IPython.display as display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -- sorry -- this is confusing\n",
    "#   DON'T load 2.0 if you are just getting data\n",
    "#   only load 2.0 if you are working through THIS notebook completely\n",
    "#   because - most of the software is not 2.0 compatible\n",
    "\n",
    "# !pip install -q tensorflow==2.0.0-beta1\n",
    "# you'll get a tensorflow-serving-api error\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# cfa code utilities\n",
    "from code.cfa_utils.tar_util import extract_tarball_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you really need TensorFlow 2.0.x\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are using tf 1.14, you need to turn on eager execution - but you should be on 2.0\n",
    "# adding it here mainly for reference, you can do most of the tf.Example tutorial in 1.14\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals\n",
    "\n",
    "you can get some test images from S3 - look for cfa_products / test_images  \n",
    "There is also a test.tfrecord (that was created as a slice of the train/val split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.getcwd()\n",
    "\n",
    "BUCKET = 'cfa-eadatasciencesb-sagemaker'\n",
    "\n",
    "S3_ALL_IMAGES = \"s3://{}/datasets/cfa_products/all_images/\".format(BUCKET)\n",
    "S3_ALL_ANNOTATIONS = \"s3://{}/datasets/cfa_products/all_annotations\".format(BUCKET)\n",
    "S3_TEST_IMAGES = \"s3://{}/datasets/cfa_products/test_images\".format(BUCKET)\n",
    "\n",
    "TARBALL_DIR = os.path.join(PROJECT_DIR, \"data/tarballs\")\n",
    "TARBALL_EXTRACT = os.path.join(PROJECT_DIR, \"data/tarball_extract\")\n",
    "\n",
    "IMAGE_DIR = os.path.join(PROJECT_DIR, \"data/jpeg_images\")\n",
    "ANNOTATION_DIR = os.path.join(PROJECT_DIR, \"data/annotations\")\n",
    "\n",
    "MODEL_PATH = os.path.join(PROJECT_DIR, \"trained_model/export/Servo/1564778509\")\n",
    "LABEL_MAP = os.path.join(PROJECT_DIR, \"code/cfa_prod_label_map.pbtxt\")\n",
    "\n",
    "# you can get data using the TrainModel_Step1_Local notebook\n",
    "TEST_TFRECORDS_PATH =  os.path.join(PROJECT_DIR, \"code/tfrecords/test/\")\n",
    "                                    \n",
    "SAMPLE_IMAGE = os.path.join(PROJECT_DIR, \"data/new_jpeg_images/20190710_variety_1562781002.jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data - choice\n",
    "0 - the data is already in IMAGE_DIR - go directly to summary  \n",
    "1 - load IMAGER_DIR w/ Large Set of Training Data  \n",
    "2 - load IMAGE_DIR w/ Test Set  \n",
    "\n",
    "select one choice - then to go summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choice 1\n",
    "# Execute THIS block for TRAINING DATA\n",
    "\n",
    "! mkdir -p /home/ec2-user/SageMaker/ssd-dag/data/tarball_extract\n",
    "# TRAINING DATA - ALL IMAGES\n",
    "# - delete tarballs first\n",
    "# - delete images first - you can comment this out if you don't like it\n",
    "! rm {TARBALL_DIR}/*.tar.gz -rf\n",
    "! rm {IMAGE_DIR}/*.jpg -rf\n",
    "! rm {ANNOTATION_DIR}/*.xml -rf\n",
    "\n",
    "# get from \n",
    "! aws s3 cp {S3_ALL_IMAGES} {TARBALL_DIR} --recursive --quiet\n",
    "\n",
    "jpg_ext = '.jpg'\n",
    "extract_tarball_directory(TARBALL_DIR, TARBALL_EXTRACT, jpg_ext, IMAGE_DIR)\n",
    "\n",
    "# TRAINING DATA - ALL ANNOTATIONS\n",
    "# - delete tarballs first\n",
    "# - delete annotations first - you can comment this out if you don't like it\n",
    "! rm {TARBALL_DIR}/*.tar.gz -rf\n",
    "! rm {ANNOTATIONS_DIR}/*.xml -rf\n",
    "\n",
    "# get from \n",
    "! aws s3 cp {S3_ALL_ANNOTATIONS} {TARBALL_DIR} --recursive --quiet\n",
    "\n",
    "xml_ext = '.xml'\n",
    "extract_tarball_directory(TARBALL_DIR, TARBALL_EXTRACT, xml_ext, ANNOTATION_DIR)\n",
    "\n",
    "# clean up\n",
    "! rm {TARBALL_DIR}/*.tar.gz -rf\n",
    "! ls {IMAGE_DIR} | wc\n",
    "! ls {ANNOTATION_DIR} | wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choice 2\n",
    "# Excecute THIS block for Test\n",
    "! rm {IMAGE_DIR}/*.jpg -rf\n",
    "! rm {ANNOTATIONS_DIR}/*.xml -rf\n",
    "\n",
    "# test images are not tarballed\n",
    "# get from S3\n",
    "! aws s3 cp {S3_TEST_IMAGES} {IMAGE_DIR} --recursive --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After choosing a data set - RESUME HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "# your files are already present\n",
    "# or you loaded a training set or you loaded a test set\n",
    "\n",
    "# Traditional - Python way to create a director\n",
    "data_root = pathlib.Path(IMAGE_DIR)\n",
    "\n",
    "# omit .gitkeep here with a glob\n",
    "trad_image_paths = list(data_root.glob('*.jpg'))\n",
    "trad_image_paths = [str(path) for path in trad_image_paths]\n",
    "\n",
    "# DON'T\n",
    "# image_paths = tf.io.gfile.listdir(IMAGE_DIR)\n",
    "# you'll get all files - including the .gitkeep file\n",
    "\n",
    "# DO \n",
    "image_glob = os.path.join(IMAGE_DIR, '*.jpg')\n",
    "tf_image_paths = tf.io.gfile.glob(image_glob)\n",
    "\n",
    "\n",
    "print (\"traditional:\", len(trad_image_paths), '\\n', trad_image_paths[:3])\n",
    "print (\"      tf.io:\", len(tf_image_paths), '\\n', tf_image_paths[:3])\n",
    "\n",
    "# conclusion - not a lot of difference, \n",
    "#   but I would say master the tf.io functions - they will make things easier \n",
    "#   for you in the long run - tailored for this use case & less code\n",
    "\n",
    "image_paths = tf_image_paths  #  just to keep the subsequent code working - use this common variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the PIL display function\n",
    "#  to display from just a path\n",
    "\n",
    "for n in range(3):\n",
    "  image_path = random.choice(image_paths)\n",
    "  display.display(display.Image(image_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Utilities\n",
    "the tutorial sez:  \n",
    "##### TensorFlow includes all the tools you need to load and process images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display an image\n",
    "#   using PIL\n",
    "img_path = image_paths[0]\n",
    "print (\"img_path:\", img_path)\n",
    "display.display(display.Image(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the image into a tensor\n",
    "# - note\n",
    "#     - with Eager on, the type is an EagerTensor\n",
    "#     - without Eager, the type is Tensor\n",
    "#\n",
    "#   When you have a EagerTensor - you can get to the value easily\n",
    "#     - numpy array but it is a serialized string of bytes\n",
    "# \n",
    "#   you can get the value of the Tensor - in bytes, but then you have to decode it\n",
    "\n",
    "img_tensor = tf.io.read_file(img_path)\n",
    "print (\"read_file:\", type(img_tensor))\n",
    "# EagerTensor prints the entire Tensor - because it's Eager - it's here, not lazy\n",
    "# - but don't do it\n",
    "# print (\"   \", img_tensor)\n",
    "\n",
    "print (\"\")\n",
    "print(repr(img_tensor)[:100]+\"...\")\n",
    "\n",
    "# tf.io.is_jpeg works with an EagerTensor\n",
    "print (tf.io.is_jpeg(img_tensor))\n",
    "\n",
    "img_numpy_bytes = img_tensor.numpy()\n",
    "print (type(img_numpy_bytes))\n",
    "print (img_numpy_bytes[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the tensor (numpy)\n",
    "# - note that an EagerTensor - the value can be printed\n",
    "# - with Eager Execution, you don't have to run the session to get the value\n",
    "\n",
    "print (\"img_tensor - from read_file is type:\", type(img_tensor), '\\n', img_tensor.dtype)\n",
    "\n",
    "# decode the string - byte array with decode_image()\n",
    "# - now you have a tensor\n",
    "img_tensor_numpy = tf.image.decode_image(img_tensor)\n",
    "print (\"deocde to a numpy Tensor:\", type(img_tensor_numpy),  '\\n', img_tensor_numpy.dtype)\n",
    "\n",
    "img_numpy_uint8 = img_tensor_numpy.numpy()\n",
    "print(\"img_numpy_uint8 type:\", type(img_numpy_uint8))\n",
    "print(\"    numpy shape:\", img_numpy_uint8.shape)\n",
    "print(\"    numpy type:\", img_numpy_uint8.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# operations on the tensor\n",
    "# -- resize - the Tensor must be byte array\n",
    "print (\"input(img_tensor_numpy):\", type(img_tensor_numpy))\n",
    "print (\"      of dtype:\", img_tensor_numpy.dtype)\n",
    "\n",
    "# after resizing, you have a Tensor, decoded, float32, NOT normalized images\n",
    "img_resized = tf.image.resize(img_tensor_numpy, [300, 300])\n",
    "print (\"tf.image.resize:\", type(img_resized))\n",
    "print (\"    of dtype:\", img_resized.dtype)\n",
    "print (\"      values:\", img_resized.numpy()[:5,:5,:5], '\\n')\n",
    "\n",
    "# you can normalize the image\n",
    "#   with a scalar-looking operation\n",
    "img_resized_normal = img_resized/255.0\n",
    "print(\"tensor type:\", type(img_resized_normal))\n",
    "print(\"tensor shape:\", img_resized_normal.shape)\n",
    "print(\"tensor range in values:\", img_resized_normal.numpy().min(), img_resized_normal.numpy().max())\n",
    "print(\"tensor data type:\", img_resized_normal.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input:   Tensor, image :  string/byte array\n",
    "# output:  Tensor, image :  float32 normalized\n",
    "def preprocess_image(image):\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  image = tf.image.resize(image, [192, 192])\n",
    "  image /= 255.0  # normalize to [0,1] range\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input:  image path\n",
    "# output: preprocess_image()\n",
    "#         Tensor, image: float32 normalized\n",
    "def load_and_preprocess_image(path):\n",
    "  image = tf.io.read_file(path)\n",
    "  return preprocess_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test our functions\n",
    "\n",
    "image_path = image_paths[0]\n",
    "\n",
    "plt.imshow(load_and_preprocess_image(img_path))\n",
    "plt.grid(False)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get length of dataset\n",
    "# - at this time, there is no simple function\n",
    "#   this is brute force - ii just want this for QA reasons\n",
    "\n",
    "def get_dataset_length(ds):\n",
    "    num_elements = 0\n",
    "    for element in ds:\n",
    "        num_elements += 1\n",
    "    return num_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample Map Function\n",
    "# input:  tf.Tensor\n",
    "def map_fn(tensor):\n",
    "    # - just trying some different functions\n",
    "    # return_value = tf.strings.length(tensor)\n",
    "    # return_value = tf.strings.substr(tensor,0,8)\n",
    "    pattern = r'.*/jpeg_images/.*142\\.jpg'\n",
    "    return_value = tf.strings.regex_full_match(tensor, pattern)\n",
    "    return return_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample Filter Function\n",
    "# takes an input\n",
    "# must return boolan (True/False)\n",
    "# - True, the record is kept\n",
    "# - False, the record is dropped\n",
    "def filter_fn(tensor):\n",
    "    # keep ONLY /jpeg_images/*142.jpg:  \n",
    "    # pattern = r'.*/jpeg_images/.*142\\.jpg'\n",
    "\n",
    "    # filter OUT any in the *2SB* group\n",
    "    # -- Error - and I never figured this out\n",
    "    #   * it is a perl error ?\n",
    "    #   doesn't like the negation (?! )\n",
    "    # pattern = r'^.*/jpeg_images/(?!.*2SB).*\\.jpg'\n",
    "    \n",
    "    # keep ONLY 2SB\n",
    "    pattern = r'^.*/jpeg_images/.*2SB.*\\.jpg'\n",
    "    match = tf.strings.regex_full_match(tensor, pattern)  # returns a Tensor type Boolean\n",
    "    # filter out matches -\n",
    "    # - to filter out - return False - but it matched True\n",
    "    # if match.numpy():\n",
    "    #    return False\n",
    "    # else:\n",
    "    #    return True\n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the contents of a Dataset\n",
    "def print_dataset_contents(ds):\n",
    "    for t in ds:\n",
    "        print (t.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSets\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "\n",
    "magic happens with a Dataset.  \n",
    "You can create a dataset from a list of file paths.\n",
    "\n",
    "You can apply a function to to each record - .map() operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the array of strings -- image paths\n",
    "# and make a dataset\n",
    "image_path_ds = tf.data.Dataset.from_tensor_slices(image_paths)\n",
    "print (\"image path dataset type:\", type(image_path_ds))\n",
    "\n",
    "#note - strings, no size\n",
    "print (\"image path dataset:\", image_path_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING - some deprecation risk \n",
    "print (\"Dataset output class:\", tf.compat.v1.data.get_output_classes(image_path_ds))\n",
    "print (\"Dataset output class shape:\", tf.compat.v1.data.get_output_shapes(image_path_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache the dataset to memory\n",
    "image_path_ds.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take n from a dataset\n",
    "print (\"Full Dataset:\", get_dataset_length(image_path_ds))\n",
    "image_path_subset_ds = image_path_ds.take(5)\n",
    "print (\"Subset Dataset:\", get_dataset_length(image_path_subset_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate on a Dataset\n",
    "each element is a EagerTensor - assuming you have Eager Execution enabled\n",
    "\n",
    "This Dataset is still just strings (Tensors containing strings).  So any operations must support type = Tensor.   See:  \n",
    "https://www.tensorflow.org/api_docs/python/tf/strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can decode every Tensor\n",
    "for t in image_path_subset_ds:\n",
    "    image_path = t.numpy().decode()\n",
    "    print (image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map on a DataSet\n",
    "Your function must take Tensor input & output.  This dataset is a string so look at tf.strings functions.    You can't just just a plain python string function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a map function == map_fn\n",
    "#  must operate & return a Tensor\n",
    "print_dataset_contents(image_path_subset_ds.map(map_fn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter a DataSet\n",
    "this dataset is a string - so, use a regex to do basic filter operations.   \n",
    "\n",
    "You can't pass parameters into your function - so all logic has to be inside the filter_fn.\n",
    "\n",
    "Below:  make sure you understand the RegEx, then incorporate it into the filter_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter using a RegE\\\n",
    "import re\n",
    "\n",
    "pattern = r'.*/jpeg_images/.*142\\.jpg'\n",
    "# pattern = r'^.*/jpeg_images/(?!.*2SB).*\\.jpg'\n",
    "sample1_text = '/home/ec2-user/SageMaker/ssd-dag/data/jpeg_images/20190531_2SB_1559319142.jpg'\n",
    "sample2_text = '/home/ec2-user/SageMaker/ssd-dag/data/jpeg_images/20190603_3MC_1559598324.jpg'\n",
    "\n",
    "sample_list = [sample1_text, sample2_text]\n",
    "\n",
    "for txt in sample_list:\n",
    "    matchObject = re.match(pattern, txt)\n",
    "    if matchObject:\n",
    "        print (\"Found:\", matchObject.group())\n",
    "    else:\n",
    "        print (\"NOT Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.match(r\"(?!.*/jpeg_images/.*412).*\\.jpg\", \"/home/jpeg_images/4324721234.jpg\")\n",
    "\n",
    "if result:\n",
    "    print (\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_filtered = image_path_subset_ds.filter(filter_fn)\n",
    "print_dataset_contents(ds_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using dataset map()\n",
    "# you can map the dataset - super cool!\n",
    "# - use the functons we defined earlier\n",
    "# - looks like it will parallelize automatically!\n",
    "\n",
    "image_ds = image_path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "print (\"image dataset type:\", type(image_path_ds))  # same type\n",
    "print (\"image dataset:\", image_path_ds)             # serialized numpy array of the normalized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can pull the value out by iterating on the Dataset\n",
    "\n",
    "for n, image in enumerate(image_ds.take(4)):\n",
    "  plt.figure(figsize=(8,8))\n",
    "  plt.subplot(2,2,n+1)\n",
    "  plt.imshow(image)\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
