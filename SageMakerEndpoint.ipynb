{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using SageMaker Endpoint\n",
    "\n",
    "## Model:  MobileNet (v1) SSD  300x300\n",
    "## Trained For:  CFA Product Images\n",
    "\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/io/encode_jpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.getcwd()\n",
    "IMAGE_DIR = os.path.join(PROJECT_DIR, \"data/new_jpeg_images\")\n",
    "\n",
    "MODEL_PATH = os.path.join(PROJECT_DIR, \"trained_model/export/Servo/1564865938\")\n",
    "LABEL_MAP = os.path.join(PROJECT_DIR, \"code/cfa_prod_label_map.pbtxt\")\n",
    "\n",
    "# you can get data using the TrainModel_Step1_Local notebook\n",
    "TEST_TFRECORDS_PATH =  os.path.join(PROJECT_DIR, \"code/tfrecords/test/\")\n",
    "                                    \n",
    "SAMPLE_IMAGE = \"/home/ec2-user/SageMaker/ssd-dag/data/jpeg_images/20190710_variety_1562781002.jpg\"\n",
    "\n",
    "# NAME - get this from the console\n",
    "ENDPOINT_NAME = \"ep-mobilenet-ssd\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.keras.preprocessing.image.load_img(SAMPLE_IMAGE, target_size=[300, 300])\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "print (type(x), x.shape)\n",
    "\n",
    "x32 = tf.keras.applications.mobilenet.preprocess_input(x[tf.newaxis,...])\n",
    "print (\"x32:\", type(x32), x32.shape, x32.dtype)\n",
    "\n",
    "x8 = x32.astype(np.uint8)\n",
    "print (\"x8:\", type(x8), x8.shape, x8.dtype)\n",
    "\n",
    "img_raw = tf.io.read_file(SAMPLE_IMAGE)\n",
    "print (\"tf.io.read_file:\", img_raw)\n",
    "\n",
    "img_tensor = repr(img_raw)\n",
    "print (\"repr:\", type(img_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Model\n",
    "\n",
    "Local Model was pulled from a successful SageMaker training job (S3 -> local) and extracted.   This verifies the training job:\n",
    "- created a saved_model.pb\n",
    "- in export/Servo/\n",
    "\n",
    "And, we can read the Signature Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Loading saved_model.py from:\", MODEL_PATH)\n",
    "loaded_model = tf.saved_model.load(sess=tf.Session(), \n",
    "                                   tags=[tf.saved_model.tag_constants.SERVING], \n",
    "                                   export_dir=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model complies to serving framework and can read signature defs\n",
    "!saved_model_cli show --dir {MODEL_PATH} --tag_set serve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signatures for:\n",
    "# - serving_default\n",
    "# - tensorflow/serving/predict\n",
    "# appear to be the same\n",
    "!saved_model_cli show --dir {MODEL_PATH} --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Endpoint\n",
    "create the endpoint assuming it doesn't already exist.  \n",
    "\n",
    "you go to the SageMaker console\n",
    "- Endpoints:  Create\n",
    "- on Create & Configure\n",
    "  - name:   ep-mobilenet-ssd  (whatever you want but the global name is in this code - above)\n",
    "  - endpoint configuration:   use the epc-mobilenet-ssd (this specifies p2.xlarge)\n",
    "  \n",
    "This will take 5-10 minutes\n",
    "\n",
    "THERE ARE MORE NOTES in the TrainModel_Step3_TrainingJob.  Creating an endpoint configuration requires knowing the inference code image (Docker?) - and I haven't figured out how to get that from the training job.\n",
    "\n",
    "if it fails...\n",
    "- retrain a model just to make sure you have a good one\n",
    "- recreate the endpoint config - this seems to be the most important artifact\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "from sagemaker.predictor import json_serializer, json_deserializer\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "predictor=sagemaker.tensorflow.model.TensorFlowPredictor(ENDPOINT_NAME, sagemaker_session)\n",
    "\n",
    "print (type(predictor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor - images\n",
    "image_tensor = tf.constant(value=x8, shape=(1, 300, 300, 3), dtype=tf.uint8, name=\"tf_example\")\n",
    "# image_tensor = tf.constant(value=x32, shape=(1, 300, 300, 3), dtype=tf.float32, name=\"tf_example\")\n",
    "print (image_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You Need a tf.Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is needed since we cloned tensorflow/models under code.\n",
    "cwd = os.getcwd()\n",
    "models = os.path.join(cwd, 'code/models/research/')\n",
    "slim = os.path.join(cwd, 'code/models/research/slim')\n",
    "sys.path.append(models)\n",
    "sys.path.append(slim)\n",
    "\n",
    "from object_detection.inference import detection_inference\n",
    "\n",
    "! ls {TEST_TFRECORDS_PATH}\n",
    "input_tfrecord_paths = [TEST_TFRECORDS_PATH]\n",
    "serialized_example_tensor, image_tensor = detection_inference.build_input( input_tfrecord_paths)\n",
    "\n",
    "print (\"serialized_example_tensor\", type(serialized_example_tensor))\n",
    "print (\"    \", serialized_example_tensor)\n",
    "print (\"    \")\n",
    "print (\"image_tensor\", image_tensor.shape)\n",
    "print (\"    \", image_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fumbling\n",
    "here is where I am trying a bunch of stuff -- that doesn't   \n",
    "\n",
    "What do we know:\n",
    "- needs a list\n",
    "- key must be in 'serialized_example', 'instances'\n",
    "- shape of the serialized\n",
    "  - list with n items generates error:  Input to reshape is a tensor with 'n' values\n",
    "  - list of 1\n",
    "    - error: [[{{node ParseSingleExample/ParseSingleExample}}]]\\n\\t [[{{node case/cond/cond_jpeg/Switch}}]]\" }\"\n",
    "    - so it looks like it can take an Example or a jpg (on a Switch) - but, can't figure out the label for jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to create a bytes list feature\n",
    "def bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "# read an image - encoded_jpg is type=bytes\n",
    "SAMPLE_IMAGE = \"/home/ec2-user/SageMaker/ssd-dag/data/jpeg_images/20190710_variety_1562781002.jpg\"\n",
    "with tf.io.gfile.GFile(SAMPLE_IMAGE, 'rb') as fid:\n",
    "    encoded_jpg = fid.read()\n",
    "print (\"encoded_jpg:\", type(encoded_jpg))  # bytes\n",
    "    \n",
    "# tf_example = <class 'tensorflow.core.example.example_pb2.Example'>\n",
    "tf_example = tf.train.Example(features=tf.train.Features(feature={'image/encoded': bytes_feature(encoded_jpg)}))\n",
    "print (\"tf_example:\", type(tf_example))\n",
    "print (\" \")\n",
    "\n",
    "tf_example1 = tf_example\n",
    "tf_example2 = tf_example\n",
    "# -- not using these serialization methods --\n",
    "\n",
    "# serialize to bytes; ser_tf_example = <class 'bytes'>\n",
    "#   binary string - see tutorial:  https://www.tensorflow.org/tutorials/load_data/tf_records\n",
    "# ser_tf_example = tf_example.SerializeToString()\n",
    "# print (\"serialized to string - tf_example:\", type(ser_tf_example))\n",
    "# print (\"    \", ser_tf_example[:20])\n",
    "\n",
    "\n",
    "\n",
    "# serialize bytes to string\n",
    "# str_ser_tf_example = ser_tf_example.decode('utf-8')\n",
    "# print (\"str serialized to string - tf_example:\", type(str_ser_tf_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialized list of Examples\n",
    "make the list of examples THEN serialize it\n",
    "\n",
    "#### Payload\n",
    "\n",
    "{'instances': '[features {\\n  feature {\\n    key: \"image/encoded\"\\n    value {\\n      bytes_list {\\n        value: \"\\\\377\\\\330\\\\377\\\\340\\\\000\\\\020JFIF\\\\000\\\\001\\\\001\\\\000\\\\000\\\\001\\\\000\\\\001\\\\000\\\\000\\\\377\\\\333\\\\000C\\\\000\\\\002\\\\001\\\\001\\\\001\\\\001\\\\001\\\\002\\\\001\\\\001\\\\001\\\\002\n",
    "\n",
    "#### Error\n",
    "\n",
    "ModelError: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from model with message \"{ \"error\": \"JSON Value: {\\n    \\\"instances\\\": {\\n        \\\"instances\\\": \\\"[features {\\\\n  feature {\\\\n    key: \\\\\\\"image/encoded\\\\\\\"\\\\n    value {\\\\n      bytes_list {\\\\n        value: \\\\\\\"\\\\\\\\377\\\\\\\\330\\\\\\\\377\\\\\\\\340\\\\\\\\000\\\\\\\\020JFIF\\\\\\\\000\\\\\\\\001\\\\\\\\001\\\\\\\\000\\\\\\\\000\\\\\\\\001\\\\\\\\000\\\\\\\\001\\\\\\\\000\\\\\\\\000\\\\\\\\377\\\\\\\\333\\\\\\\\00\n",
    "\n",
    "Excepting 'instances' to be an list/array\" }\". See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/ep-mobilenet-ssd in account 586454201570 for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_ex1 = \"{}\".format(serialized_example_tensor)\n",
    "ser_instance1 = {\"serialized_example\": ser_ex1}\n",
    "print (ser_instance1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of Instances (Examples)\n",
    "\n",
    "the list of instances MUST be just 1 item.\n",
    "\n",
    "e.g.  if you have a list of 2 items:  \n",
    "ModelError: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from model with message \"{ \"error\": \"Input to reshape is a tensor with 2 values, but the requested shape has 1\\n\\t [[{{node Reshape}}]]\" }\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of instances\n",
    "\n",
    "ser_ex1 = \"{}\".format(tf_example1)\n",
    "ser_instance1 = {\"serialized_example\": ser_ex1}\n",
    "# print (ser_instance1)\n",
    "\n",
    "ser_ex2 = \"{}\".format(tf_example2)\n",
    "ser_instance2 = {\"serialized_example\": ser_ex2}\n",
    "# print (ser_instance2)\n",
    "ser_instance_list = [ser_instance1] #, ser_instance2, ser_instance1]\n",
    "\n",
    "print (ser_instance_list)\n",
    "predict_dict = ser_instance_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of numpy arrays\n",
    "\n",
    "No, doesn't seem to be the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(x32).tolist()\n",
    "print (type(data))\n",
    "ser_image = \"{}\".format(x32)\n",
    "ser_image_list = [ser_image]\n",
    "# predict_dict = {'serialized_example': ser_image_list}\n",
    "predict_dict = {'instances': ser_image_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Choosing ONE:\n",
    "#### Serialized List of Examples\n",
    "#### List of Serialized Examples\n",
    "\n",
    "### run this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict to string\n",
    "predict_string = json.dumps(predict_dict)\n",
    "predict_json = json.loads(predict_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (predict_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = predictor.predict(predict_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json = json.dumps({\"signature_name\": \"serving_default\", \"instances\": x32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(SAMPLE_IMAGE, 1)\n",
    "\n",
    "# resize, as our model is expecting images in 32x32.\n",
    "# image = cv2.resize(image, (32, 32))\n",
    "image = cv2.resize(image, (300,300))\n",
    "print (\"data type:\", type(image), image.shape)\n",
    "#image = x32\n",
    "\n",
    "data = {'instances': np.asarray(image).astype(float).tolist()}\n",
    "\n",
    "# The request and response format is JSON for TensorFlow Serving.\n",
    "# For more information: https://www.tensorflow.org/serving/api_rest#predict_api\n",
    "predictor.accept = 'application/json'\n",
    "predictor.content_type = 'application/json'\n",
    "\n",
    "predictor.serializer = json_serializer\n",
    "predictor.deserializer = json_deserializer\n",
    "\n",
    "# For more information on the predictor class.\n",
    "# https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/predictor.py\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
