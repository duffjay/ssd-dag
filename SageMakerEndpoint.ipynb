{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict using SageMaker Endpoint\n",
    "\n",
    "## Model:  MobileNet (v1) SSD  300x300\n",
    "## Trained For:  CFA Product Images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.getcwd()\n",
    "IMAGE_DIR = os.path.join(PROJECT_DIR, \"data/new_jpeg_images\")\n",
    "\n",
    "MODEL_PATH = os.path.join(PROJECT_DIR, \"trained_model/export/Servo/1564865938\")\n",
    "LABEL_MAP = os.path.join(PROJECT_DIR, \"code/cfa_prod_label_map.pbtxt\")\n",
    "\n",
    "# you can get data using the TrainModel_Step1_Local notebook\n",
    "TEST_TFRECORDS_PATH =  os.path.join(PROJECT_DIR, \"code/tfrecords/test/\")\n",
    "                                    \n",
    "SAMPLE_IMAGE = \"/home/ec2-user/SageMaker/ssd-dag/data/jpeg_images/20190710_variety_1562781002.jpg\"\n",
    "\n",
    "# NAME - get this from the console\n",
    "ENDPOINT_NAME = \"ep-mobilenet-ssd2\"  # probably not ssd2,  ssd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.keras.preprocessing.image.load_img(SAMPLE_IMAGE, target_size=[300, 300])\n",
    "plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "print (type(x), x.shape)\n",
    "\n",
    "x32 = tf.keras.applications.mobilenet.preprocess_input(x[tf.newaxis,...])\n",
    "print (\"x32:\", type(x32), x32.shape, x32.dtype)\n",
    "\n",
    "x8 = x32.astype(np.uint8)\n",
    "print (\"x8:\", type(x8), x8.shape, x8.dtype)\n",
    "\n",
    "img_raw = tf.io.read_file(SAMPLE_IMAGE)\n",
    "print (\"tf.io.read_file:\", img_raw)\n",
    "\n",
    "img_tensor = repr(img_raw)\n",
    "print (\"repr:\", type(img_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Model\n",
    "\n",
    "Local Model was pulled from a successful SageMaker training job (S3 -> local) and extracted.   This verifies the training job:\n",
    "- created a saved_model.pb\n",
    "- in export/Servo/\n",
    "\n",
    "And, we can read the Signature Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Loading saved_model.py from:\", MODEL_PATH)\n",
    "loaded_model = tf.saved_model.load(sess=tf.Session(), \n",
    "                                   tags=[tf.saved_model.tag_constants.SERVING], \n",
    "                                   export_dir=MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model complies to serving framework and can read signature defs\n",
    "!saved_model_cli show --dir {MODEL_PATH} --tag_set serve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signatures for:\n",
    "# - serving_default\n",
    "# - tensorflow/serving/predict\n",
    "# appear to be the same\n",
    "!saved_model_cli show --dir {MODEL_PATH} --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Endpoint\n",
    "create the endpoint assuming it doesn't already exist.  \n",
    "\n",
    "you go to the SageMaker console\n",
    "- Endpoints:  Create\n",
    "- on Create & Configure\n",
    "  - name:   ep-mobilenet-ssd  (whatever you want but the global name is in this code - above)\n",
    "  - endpoint configuration:   use the epc-mobilenet-ssd (this specifies p2.xlarge)\n",
    "  \n",
    "This will take 5-10 minutes\n",
    "\n",
    "if it fails...\n",
    "- retrain a model just to make sure you have a good one\n",
    "- recreate the endpoint config - this seems to be the most important artifact\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "from sagemaker.predictor import json_serializer, json_deserializer\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "predictor=sagemaker.tensorflow.model.TensorFlowPredictor(ENDPOINT_NAME, sagemaker_session)\n",
    "\n",
    "print (type(predictor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor = tf.constant(value=x8, shape=(1, 300, 300, 3), dtype=tf.uint8, name=\"tf_example\")\n",
    "# image_tensor = tf.constant(value=x32, shape=(1, 300, 300, 3), dtype=tf.float32, name=\"tf_example\")\n",
    "print (image_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You Need a tf.Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed since we cloned tensorflow/models under code.\n",
    "cwd = os.getcwd()\n",
    "models = os.path.join(cwd, 'code/models/research/')\n",
    "slim = os.path.join(cwd, 'code/models/research/slim')\n",
    "sys.path.append(models)\n",
    "sys.path.append(slim)\n",
    "\n",
    "from object_detection.inference import detection_inference\n",
    "\n",
    "! ls {TEST_TFRECORDS_PATH}\n",
    "input_tfrecord_paths = [TEST_TFRECORDS_PATH]\n",
    "serialized_example_tensor, image_tensor = detection_inference.build_input( input_tfrecord_paths)\n",
    "\n",
    "print (\"serialized_example_tensor\", serialized_example_tensor)\n",
    "print (\"image_tensor\", image_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print (\"data type:\", type(x8))\n",
    "data=  np.random.randn(1, 784)\n",
    "# Object of type 'Tensor' is not JSON serializable\n",
    "# - so it must be looking for JSON\n",
    "# output_dict = predictor.predict(image_tensor)  \n",
    "\n",
    "# Tensor not serializable\n",
    "# output_dict = predictor.predict({\"tf_example\": image_tensor})\n",
    "\n",
    "# ModelError: An error occurred (ModelError) when calling the InvokeEndpoint operation: \n",
    "#  Received client error (400) from model with message \n",
    "#  \"{ \"error\": \"Failed to process element: 0 key: tf_example of 'instances' list. \n",
    "#   Error: Invalid argument: JSON object: does not have named input: tf_example\" }\". \n",
    "# See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/ep-mobilenet-ssd \n",
    "# in account 586454201570 for more information.\n",
    "# output_dict = predictor.predict({\"tf_example\": x8})\n",
    "\n",
    "# ModelError: An error occurred (ModelError) when calling the InvokeEndpoint operation: \n",
    "#  Received client error (400) from model with message \n",
    "#  \"{ \"error\": \"Failed to process element: 0 key: serialized_example of 'instances' list. \n",
    "#  Error: Invalid argument: JSON Value: 0 Type: Number is not of expected type: string\" }\". \n",
    "#  See https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpoints/ep-mobilenet-ssd \n",
    "#  in account 586454201570 for more information.\n",
    "# output_dict = predictor.predict({\"serialized_example\": data})\n",
    "\n",
    "# ModelError: An error occurred (ModelError) when calling the InvokeEndpoint operation: \n",
    "# Received client error (400) from model with message \n",
    "# \"{ \"error\": \"Could not parse example input, value: \\'<tf.Tensor \\'ReadFile:0\\' \n",
    "#    shape=() dtype=string>\\'\\n\\t [[{{node ParseSingleExample/ParseSingleExample}}]]\\n\\t \n",
    "#  [[{{node case/cond/cond_jpeg/Switch}}]]\" }\". See https://us-east-1.console.aws.amazon.com/\n",
    "# cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/\n",
    "# Endpoints/ep-mobilenet-ssd in account 586454201570 for more information.\n",
    "output_dict = predictor.predict({\"serialized_example\": img_tensor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json = json.dumps({\"signature_name\": \"serving_default\", \"instances\": x32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(SAMPLE_IMAGE, 1)\n",
    "\n",
    "# resize, as our model is expecting images in 32x32.\n",
    "# image = cv2.resize(image, (32, 32))\n",
    "image = cv2.resize(image, (300,300))\n",
    "print (\"data type:\", type(image), image.shape)\n",
    "#image = x32\n",
    "\n",
    "data = {'instances': np.asarray(image).astype(float).tolist()}\n",
    "\n",
    "# The request and response format is JSON for TensorFlow Serving.\n",
    "# For more information: https://www.tensorflow.org/serving/api_rest#predict_api\n",
    "predictor.accept = 'application/json'\n",
    "predictor.content_type = 'application/json'\n",
    "\n",
    "predictor.serializer = json_serializer\n",
    "predictor.deserializer = json_deserializer\n",
    "\n",
    "# For more information on the predictor class.\n",
    "# https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/predictor.py\n",
    "predictor.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
