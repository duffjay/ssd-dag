{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "## Step 2 - Test your train.py with Docker\n",
    "\n",
    " USE SAGEMAKER.   Don't get confused - running jobs on the local SageMaker server isn't really what it was designed for.  It is designed to take your program and send it to outside resouces (using a Docker container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-TensorFlow 2.0\n",
    "# set up eager execution\n",
    "tf.enable_eager_execution()\n",
    "tf.set_random_seed(0)\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker\n",
    "Set up Docker - if this is an instance with a GPU, it will configure accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/bin/bash ./sagemaker_docker_setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a local SageMaker estimator\n",
    "\n",
    "code/train_model - this entire directory goes to the Docker image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an Estimator is a SageMaker class\n",
    "# and, you're using the tensorflow flavor\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '/opt/ml/model'     # this is related to how it gets deployed in the Docker\n",
    "                                # this is a SAGEMAKER thing - don't confuse with the model_dir \n",
    "                                # that we have inside our code\n",
    "    \n",
    "train_instance_type = 'local'   # local vs another server\n",
    "\n",
    "hyperparameters = {'epochs': 5, 'batch_size': 128, 'learning_rate': 0.01}\n",
    "\n",
    "# python modules that need to be loaded in the Docker\n",
    "# what you have installed here has to be loaded there\n",
    "env = { 'SAGEMAKER_REQUIREMENTS' : 'requirements.txt'}\n",
    "\n",
    "# SageMaker Execution Role\n",
    "# role = sagemaker.get_execution_role()\n",
    "# since this doesn't work, get it manually from IAM\n",
    "role = 'arn:aws:iam::586454201570:role/MLAM_SageMakerExecution'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {'train' : f'file://code/tfrecords/train', 'test' : f'file://code/tfrecords/eval'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_estimator = TensorFlow(entry_point='train.py',\n",
    "                       source_dir='code',\n",
    "                       model_dir=model_dir,\n",
    "                       train_instance_type=train_instance_type,\n",
    "                       train_instance_count=1,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       role=role,\n",
    "                       base_job_name='cfa_products_mobilenet_v1_SSD',\n",
    "                       framework_version='1.13',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
