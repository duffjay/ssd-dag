{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Model\n",
    "## Step 2 - Deploy Model as TensorFlow to an endpoint\n",
    "This is consistent with the AWS Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.eager.python import tfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = os.getcwd()\n",
    "IMAGE_DIR = os.path.join(PROJECT_DIR, \"data/new_jpeg_immages\")\n",
    "TENSORFLOW_FROZEN_GRAPH = os.path.join(PROJECT_DIR, \"tensorflow_model/saved_model/saved_model.pb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE - you may have to change this if you  do/don't have a GPU on the instance\n",
    "#      - if you are using a pX.Xxlarge (e.g. p2 or p3) - you have a GPU\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "# device = '/cpu:0' \n",
    "device = '/gpu:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the TENSORFLOW model (not Lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.eager.python import tfe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model from Frozen Graph (protobuf)\n",
    "Remember:\n",
    "- the training ended with a checkpoint\n",
    "- the convert_checkpoint_to_edgetpu_tflite.sh script:\n",
    "  - converted the checkpoint to a frozen TENSORFLOW graph (THIS IS WHAT WE WANT)\n",
    "  - converted the checkpoint to a frozen TensorFlow Lite graph\n",
    "  - then converted the frozen graph to a TFLite model (*.tflite)\n",
    "  \n",
    "The TENSORFLOW frozen graph was put in tensorflow_model/saved_momdel\n",
    "  \n",
    "reference:  \n",
    "https://github.com/viplix3/SSD-tensorflow/blob/master/Testing.ipynb\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "Is the image normalized???\n",
    "See the graph parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
