{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding\n",
    "## TensorFlow tf.io API for Python\n",
    "\n",
    "### Go through UnderstandingImages FIRST.   Then this worksheet.   \n",
    "UnderstandingImages will get the image data - a prerequisite for this notebook.\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/io\n",
    "\n",
    "be careful with version v1.14 & v2.0\n",
    "\n",
    "### TensorFlow Python Ops\n",
    "a bunch of helper functions  \n",
    "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/ops\n",
    "\n",
    "tensorflow.python.framework\n",
    "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/framework\n",
    "\n",
    "Why - These standard routines will help you with file I/O and creating data for TensorFlow.  Use these utilities wherever possible!!\n",
    "\n",
    "Look at UnderstandingExample after this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import string_ops, math_ops\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment - Eager Execution\n",
    "you can run this notebook:\n",
    "- without Eager Execution - you'll see Tensors but no data (because of lazy execution of the DAG)\n",
    "- with Eager Execution - you'll see values\n",
    "\n",
    "Eager Execution is default with TF 2.0\n",
    "\n",
    "So, try  running with & without executinb the next block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALs\n",
    "\n",
    "PROJECT_DIR = os.getcwd()\n",
    "IMAGE_DIR = os.path.join(PROJECT_DIR, \"data/jpeg_images\")\n",
    "SAMPLE_IMAGE = \"20190710_variety_1562781002.jpg\"\n",
    "\n",
    "MODEL_PATH = os.path.join(PROJECT_DIR, \"trained_model/export/Servo/1564865938\")\n",
    "LABEL_MAP = os.path.join(PROJECT_DIR, \"code/cfa_prod_label_map.pbtxt\")\n",
    "\n",
    "# you can get data using the TrainModel_Step1_Local notebook\n",
    "TEST_TFRECORDS_PATH =  os.path.join(PROJECT_DIR, \"code/tfrecords/test/\")\n",
    "                                    \n",
    "SAMPLE_IMAGE = \"/home/ec2-user/SageMaker/ssd-dag/data/jpeg_images/20190710_variety_1562781002.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.io.gfile\n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/io/gfile\n",
    "\n",
    "Note that common file i/o commands can be accomplished with this class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple directory list\n",
    "file_list = tf.io.gfile.listdir(IMAGE_DIR)\n",
    "file_list_length = len(file_list)\n",
    "print (\"directory list length:\", file_list_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory list based on a glob\n",
    "glob = IMAGE_DIR + '/*9.jpg'\n",
    "print (glob)\n",
    "file_list = tf.io.gfile.glob(glob)\n",
    "file_list_length = len(file_list)\n",
    "print (\"directory list length:\", file_list_length)\n",
    "sample_image = file_list[0]\n",
    "\n",
    "# note - full path \n",
    "print (sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read an image - encoded_jpg is type=bytes\n",
    "# sample_image - from above, not SAMPLE_IMAGE - the global\n",
    "\n",
    "with tf.io.gfile.GFile(sample_image, 'rb') as fid:\n",
    "    encoded_jpg = fid.read()\n",
    "print (\"encoded_jpg:\", type(encoded_jpg))  # bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Image Comparison\n",
    "- tf.io.gfile.GFile => encoded bytes\n",
    "- tf.io.read_file   => Tensor\n",
    "- tf.keras...       => PIL.Image.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.io.read_file\n",
    "image = tf.io.read_file(sample_image)\n",
    "print (\"tf.io.read_file:\", type(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.keras\n",
    "better for manipulating the data, shape, type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras\n",
    "image = tf.keras.preprocessing.image.load_img(sample_image, target_size=[300, 300])\n",
    "print (type(image))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert PIL.Image.Image => numpy array\n",
    "# - Normalized\n",
    "x = tf.keras.preprocessing.image.img_to_array(image)\n",
    "print (type(x), x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess - as req'd by MobileNet - to get add the instance dimension\n",
    "x32 = tf.keras.applications.mobilenet.preprocess_input(x[tf.newaxis,...])\n",
    "print (\"x32:\", type(x32), x32.shape, x32.dtype)\n",
    "print (\"one pixel RGB - normalized:\", x32[0,1,1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsigned 8 bit\n",
    "x8 = x32.astype(np.uint8)\n",
    "print (\"x8:\", type(x8), x8.shape, x8.dtype)\n",
    "print (\"one pixel RGB - uint8:\", x8[0,1,1,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jpeg utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_jpeg\n",
    "# ??  is Eager Execution on ??\n",
    "#  -- if NO, then the read operation creates the tensor - but it is empty (lazy)\n",
    "#     and is_jpeg doesn't work\n",
    "#  -- if YES, then you have an EagerTensor - with data\n",
    "#     and this works\n",
    "\n",
    "# takes a byte string\n",
    "with tf.io.gfile.GFile(sample_image, 'rb') as fid:\n",
    "    encoded_jpg = fid.read()\n",
    "\n",
    "jpeg_prefix = b'\\xff\\xd8\\xff'\n",
    "print (encoded_jpg[0:3], '\\n', jpeg_prefix)\n",
    "\n",
    "print ('prefix equality test:', (encoded_jpg[:3] == jpeg_prefix))\n",
    "\n",
    "# the source code shows:\n",
    "contents = encoded_jpg\n",
    "\n",
    "substr = string_ops.substr(contents, 0, 3)\n",
    "return_value = math_ops.equal(substr, b'\\xff\\xd8\\xff')  # name omitted\n",
    "print ('return_value:', return_value)\n",
    "\n",
    "funct_return = tf.io.is_jpeg(encoded_jpg)\n",
    "print ('funct_return:', funct_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"image file:\", sample_image)\n",
    "image_tensor = tf.io.read_file(sample_image)\n",
    "print (\"read_file yields:\", type(image_tensor))\n",
    "print (\"    \", image_tensor)\n",
    "print (\"is_jpeg:\", tf.io.is_jpeg(image_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode_base64\n",
    "# - decode byte string to a Tensor\n",
    "\n",
    "# - ERROR - something is wrong here\n",
    "#   - not dealing with it now\n",
    "# decoded64_image = tf.io.decode_base64(encoded_jpg)\n",
    "# print (\"decoded:\", type(decoded64_image))\n",
    "# print (decoded64_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode & crop\n",
    "# - assuming this is a 300,300,3 input image\n",
    "# Note:\n",
    "# - result is a Tensor - shaped, type: uint8\n",
    "# - assuming you can grayscale it in the operation also with channels = 1 even though input was 3\n",
    "dec_crop_image = tf.io.decode_and_crop_jpeg(encoded_jpg, [100,100,20,20], channels=1)\n",
    "print (\"decoded & cropped\")\n",
    "print (type(dec_crop_image))\n",
    "print (dec_crop_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode_image\n",
    "# - figure out the format\n",
    "\n",
    "result = tf.io.decode_image(encoded_jpg,\n",
    "                           channels=None,\n",
    "                           dtype=tf.dtypes.uint8,\n",
    "                           name=None,\n",
    "                           expand_animations=True)\n",
    "print (type(result))\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
