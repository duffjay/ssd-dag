{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "#### tensorflow_p36 environment\n",
    "\n",
    "There are several ways to run this code\n",
    "- on a SageMaker notebook (the original intent)\n",
    "- on a physical machine with a well configured dev environment\n",
    "- on a physical machine using a Docker (grilledclub/cuda-100-tf114:*)\n",
    "\n",
    "## Step 1 - Develop a train.py script\n",
    "\n",
    "This is SageMaker Script Mode.   This is relatively new and much easier than the original SageMaker design.   You need to develop a train.py program that will:\n",
    "1. run locally - that means it will run on the local resources\n",
    "2. then you will test it locally with a Docker test\n",
    "\n",
    "If it runs in these tests, then it will/should run fine when you create a SageMaker Training job.   THIS IS THE CORRECT WAY TO USE SAGEMAKER.   Don't get confused - running jobs on the local SageMaker server isn't really what it was designed for.  It is designed to take your program and send it to outside resouces (using a Docker container)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker is at 1.15\n",
    "# - kernel = conda_python3\n",
    "# ! pip install tensorflow-gpu==1.14\n",
    "#\n",
    "# - kernel = conda_tensorflow_p36\n",
    "#   1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2018 NVIDIA Corporation\r\n",
      "Built on Sat_Aug_25_21:08:01_CDT_2018\r\n",
      "Cuda compilation tools, release 10.0, V10.0.130\r\n"
     ]
    }
   ],
   "source": [
    "# currently CUDA 10.0\n",
    "! nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nvidia-smi\n",
    "this will show you how much memory is available in the GPU.   This is important if you start getting OOM (out of memory) errors.\n",
    "\n",
    "SageMaker p2.xlarge == 10+ GB  \n",
    "Note what is available.\n",
    "\n",
    "you can run (at a terminal)    \n",
    "  $ nvidia-smi -l 1   \n",
    "to see the GPU being used during training.  On SageMaker, you'll see the GPU is about 50% busy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 26 11:50:40 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce GTX 1080    On   | 00000000:01:00.0  On |                  N/A |\r\n",
      "| 35%   55C    P0    55W / 180W |   1042MiB /  8117MiB |     30%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1918      G   /usr/lib/xorg/Xorg                            56MiB |\r\n",
      "|    0      2133      G   /usr/bin/gnome-shell                          49MiB |\r\n",
      "|    0      2743      G   /usr/lib/xorg/Xorg                           474MiB |\r\n",
      "|    0      3384      G   ...AAAAAAAAAAAAAAgAAAAAAAAA --shared-files   198MiB |\r\n",
      "|    0      6754      G   ...quest-channel-token=4821165896975129716    49MiB |\r\n",
      "|    0     25702      G   gnome-control-center                          11MiB |\r\n",
      "|    0     27682      G   /usr/bin/gnome-shell                         195MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your GPU\n",
    "this should verify your GPU is correct\n",
    "\n",
    "## WARNING\n",
    "this is a good test but...  \n",
    "If you run it, it may not release  the GPU memory.   I didn't figure this out fully.   When I ran it, I would get an OOM error when the model started the training cycle - even with super small batch size.   So, something is up here.   You could play around and try stopping the notebook - check nvidia-smi to verify it released the GPU RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet Model\n",
    "Why use a MobileNet Model?  Because the end objective is a lightweight model - one that will run on a Googl Coral TPU.    This requires a quantized model (int8 - not float32).  And, you get there from a TensorFlow Lite model.  The recommended path is to start with a model structure that you know is compatible (MobileNet) then retrain on top of it.  \n",
    "1. We pull the MobileNet v1 (there is a v2 that we aren't using) trained on COCO images\n",
    "2. We train on top of it (xfer learning) with our CFA Products\n",
    "3. That generates a TensorFlow Lite model (.tflite)\n",
    "4. We will later conver .tflite to an edge TPU model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project directory: /media/home/jay/projects/ssd-dag\n",
      "code directory: /media/home/jay/projects/ssd-dag/code\n",
      "task directory: /media/home/jay/projects/ssd-dag/tasks\n"
     ]
    }
   ],
   "source": [
    "# S3_TFRECORDS_PATH = \"s3://cfa-eadatasciencesb-sagemaker/datasets/cfa_products/tfrecords/\"\n",
    "# TFRECORDS_TARBALL = \"20190718_tfrecords.tar.gz\"\n",
    "S3_TFRECORDS_PATH = \"s3://cfa-eadatasciencesb-sagemaker/datasets/security/tfrecords/\"\n",
    "TFRECORDS_TARBALL = \"20200323_tfrecords.tar.gz\"\n",
    "\n",
    "\n",
    "S3_MODEL_PATH = \"s3://cfa-eadatasciencesb-sagemaker/trained-models/tensorflow_mobilenet/\"\n",
    "# base model - starting point that we train on top of\n",
    "BASE_MODEL_FOLDER = \"20180718_coco14_mobilenet_v1_ssd300_quantized\"\n",
    "\n",
    "# our CFA model\n",
    "# note the COINCIDENCE - 2018-0718 vs 2019-0718, don't let this confuse you!\n",
    "CFA_MODEL_FOLDER = \"20190718_cfa_prod_mobilenet_v1_ssd300/\"\n",
    "\n",
    "# project directories\n",
    "PROJECT = os.getcwd()\n",
    "CODE = os.path.join(PROJECT, \"code\")\n",
    "TASKS = os.path.join(PROJECT, \"tasks\")\n",
    "MODEL_OUTPUT = os.path.join(CODE, 'model')\n",
    "\n",
    "print (\"project directory:\", PROJECT)\n",
    "print (\"code directory:\", CODE)\n",
    "print (\"task directory:\", TASKS)\n",
    "\n",
    "# Link to Security Project\n",
    "CAMERA_API = os.path.abspath(os.path.join(PROJECT, '..', 'camera-api'))\n",
    "CAMERA_API_MODEL = os.path.join(CAMERA_API, 'model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data - 1x only\n",
    "\n",
    "Get the data from s3.  You only need to pull the data once - unless of course you update it.  you'll need to pass a directory into the training job\n",
    "\n",
    "### NOTE\n",
    "still unclear if data is in the Docker or passed in with the SageMaker job  \n",
    "TODO - figure this out, it's faster to NOT put it in the Docker (code/tfrecords), it just makes the Docker step slower.   the AWS fetch when the Docker starts is much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical or Docker\n",
    "# you can run the script\n",
    "# $ cd /task\n",
    "\n",
    "# check the Globals values in the script\n",
    "# $ bash local_get_s3_files.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAGEMAKER\n",
    "#  you're in top project directory\n",
    "s3_tfrecords = os.path.join(S3_TFRECORDS_PATH, TFRECORDS_TARBALL)\n",
    "print (s3_tfrecords)\n",
    "! aws s3 cp $s3_tfrecords code/tfrecords  \n",
    "\n",
    "# tarball is now in code/tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tar -xvf code/tfrecords/$TFRECORDS_TARBALL --strip=1 -C code/tfrecords\n",
    "\n",
    "# tfrecords are all in the tfrecords/ directory\n",
    "# SageMaker likes train/test subdirectories\n",
    "# - warning - confusion with 'test' vs 'eval'\n",
    "#      I feel eval is the post train loop to evaluate the training loop - thus called val(uaion)\n",
    "#         and test is to test a model with random real-world data\n",
    "#      SageMaker calls what I call val == test\n",
    "! pwd\n",
    "! rm code/tfrecords/train/*.tfrecord* -f\n",
    "! rm code/tfrecords/val/*.tfrecord*   -f\n",
    "! rm code/tfrecords/test/*.tfrecord* -f\n",
    "\n",
    "! mv code/tfrecords/train*.* code/tfrecords/train\n",
    "! mv code/tfrecords/val*.* code/tfrecords/val\n",
    "! mv code/tfrecords/test*.* code/tfrecords/test\n",
    "\n",
    "! rm code/tfrecords/$TFRECORDS_TARBALL\n",
    "\n",
    "# tarball is gone, tfrecord files are in code/tfrecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model - 1x only\n",
    "\n",
    "You only have to pull the model once.  This exercise will RETRAIN an existing model.  So, you need the starting point.  In this example, we are training on top of the BASE == MobileNet V1 that was trained with COCO images.   You could train on top of a CFA model - just make sure you config everything properly.\n",
    "\n",
    "Copy the model from S3.    You are coping a model from an S3 folder.  There may be a label map and config file - that would make sense so you can reproduce that model.   However, if you are training on top of this model - those files aren't useful - MAKE SURE YOU UNDERSTAND THIS.   \n",
    "\n",
    "So when you pull the model from the folder - just make sure you understand if you are re-using those meta files (e.g. reproducing a model) or or if you need something new (xfer learning).  The training process will NOT read from this download.  The training program will read the config from the code/ just to help avoid this confusion.\n",
    "\n",
    "#### CKPT\n",
    "When you retrain, the config file has a train_config / fine_tune_checkpoint attribute.  You are going to download this BASE model and put it in the code/ckpt/ directory.   The training job will start with the checkpoint file you specify.   For example:\n",
    "\n",
    "fine_tune_checkpoint: \"ckpt/model.ckpt\"\n",
    "\n",
    "#### WARNING code/ckpt/checkpoints\n",
    "When you run training, it will checkpoint to code/ckpt/checkpoints.  \n",
    "- if you train for 5000 steps, then repeat, it will do nothing basically because it will just reload the 5000 checkpoint file.\n",
    "- then you'll think you're smart and you'll remove the 5000 checkpoint file.  Not so fast bucko!\n",
    "- because then you'll discover  there is some pointer in the checkpoints/ that told the system the 5000 checkpoint exists - but now it doesn't because you just wiped it - so you'll get an error (that's difficult to figure out)\n",
    "\n",
    "just delete the checkpoints directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical or Docker\n",
    "# - you may have to delete stuff first\n",
    "# $ cd code\n",
    "# $ rm -rf models\n",
    "\n",
    "# $ cd ../tasks\n",
    "# $ bash install_tf_models.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker (& Local?)\n",
    "# -- warning - something not right here\n",
    "#    I think you have to do this local or SageMaker (gotta have a base model)\n",
    "s3_model_folder = os.path.join(S3_MODEL_PATH, BASE_MODEL_FOLDER)\n",
    "! aws s3 cp $s3_model_folder code/ckpt --recursive\n",
    "\n",
    "# code/ckpt now has model.ckpt.* files\n",
    "# there is also a pipeline.config file (this one was configured for the Google Coral - you don't want it)\n",
    "# there are also some tflite files - we don't want them either"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### github tensorflow/models - 1x Only\n",
    "manually git clone the FIRST TIME.   The official TensorFlow github repo has a related repo with a bunch of models, tutorials, utilities etc.   We are using them.  So clone them to this machine.   In a subsequent step, we'll get the files we need from this local copy.\n",
    "\n",
    "!! - hold it -  \n",
    "!! this doesn't make sense, try not doing this - I don't think you need to git clone  \n",
    "!! doesn't the install_tf_models.sh do all of this?  \n",
    "!! I think we no longer copy, set just clone to code/models\n",
    "!! thus, you don't need this manual git clone, just run install_tf_models.sh in the next cell\n",
    "\n",
    "\n",
    "PHYSICAL COMPUTER  \n",
    "`cd ~/projects`  \n",
    "SAGEMAKER  \n",
    "`you should be in the SageMaker directory`  \n",
    "\n",
    "#### this will put /models into ~/projects  (you'll have ~/projects/models)\n",
    "`git clone https://github.com/tensorflow/models.git`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 time only\n",
    "\n",
    "# get the latest software\n",
    "# - git clone (to <project>/code/models)\n",
    "# - get the protobuf compiler\n",
    "# - compile the protobufs\n",
    "# - clean up\n",
    "os.chdir(TASKS)\n",
    "! ./install_tf_models.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local (Script) Mode Training\n",
    "\n",
    "#### -> if you know what you're doing, (you have a working SageMaker HOSTED training job) - you can jump out here!\n",
    "\n",
    "see the AWS SageMaker tutorials notably:  \n",
    "https://github.com/aws-samples/amazon-sagemaker-script-mode/blob/master/tf-eager-script-mode/tf-eager-sm-scriptmode.ipynb\n",
    "\n",
    "The point here is, you can develop a training script locally, then know (have a high degree of confidence) it will run as a SageMaker training job.   (This is relatively new, the old way was more difficult and cumbersome.)\n",
    "\n",
    "### What is Local?\n",
    "- local on THIS SageMaker Notebook (EC2) server\n",
    "  - p2.xlarge - no problem\n",
    "  - t2.medium - probably not (I think this is the same footprint as the feeble Workspace)\n",
    "- A desktop computer.\n",
    "  - works great on an Ubuntu laptop with GPU\n",
    "  - should work on a Windows laptop if you have a python environment set up\n",
    "- An AWS Workspace - not enough memory, you'll get a memory error.   The code runs - but fails on a memory allocation error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do you have a training script that will run locally - without Docker?\n",
    "\n",
    "considering what is coming up, you want all code needed to train in one directory. (in this example, that will be the code/ directory.) That directory will be included in the Docker image.    \n",
    "\n",
    "This is going to get a little more cumbersome because we took a bunch of stuff from the (official) github tensorflow/models project.   - we are using the MobileNet model and a BUNCH of utilities.    To make sure we keep up to date, we will get all of this programmatically - i.e. clone the most recent version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training Configuration\n",
    "\n",
    "trained-models/ may have a config file and a label map in the directories.  You can start with one of these.  BUT - there may be environmental variable values that you don't want - and you don't want the s3 pull operation to keep overwriting your config.   So, you can pull a model from s3.  Review the .config and label map files BUT !!! put YOUR config & label map file in the code/ directory.\n",
    "\n",
    "#### .config file\n",
    "See the config file for all parameters. the IN USE .config file is in the code/ direcory But you DEFINITELY need to look at these!\n",
    "- num_classes = should be consistent with labels.txt & label map\n",
    "- label_map_path (train & eval)\n",
    "    - there may be one in the model/ (that you pulled from s3)\n",
    "    - but move your desired label map to code/\n",
    "- inputs (train & eval) - not sure, SageMaker is passing that in\n",
    "- check all of the path statements \n",
    "- fine_tune_checkpoint - make sure you are fine tuning the correct file\n",
    "    - don't cross a _v1 with a _v2 - that definitely work\n",
    "   \n",
    "#### label map .pbtxt\n",
    "- classes start with 1 (not 0 based)\n",
    "- make sure your label map class count matches the config file\n",
    "- and it should match the label \n",
    "\n",
    "#### NOTE - a missing file will generate a complex error message.  NOT something as simple as file not found. \n",
    "\n",
    "#### NOTE - --model_dir parameter: \n",
    "- local mode, it needs to be model\n",
    "- SageMaker HOST mode, it needs to be /opt/ml/model\n",
    "\n",
    "--num_train_steps  \n",
    "   500 very quick test  \n",
    "   5000 more like it  \n",
    "-- num_eval_steps  \n",
    "   10 verify quick test  \n",
    "   100 more like it\n",
    "   \n",
    "beware of batch size - if you run out of GPU memory - see the config file, batch_size: 32;  you may need to decrease it if you have a small GPU\n",
    "\n",
    "GPU should be 95% utilized.  \n",
    "`nvidia-smi -l 1`\n",
    "CPU will be about 30%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(CODE)   # this will be the training directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r model\n",
    "! mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! Warning !!!\n",
    "# I changed the pipeline_config_path = local*.config\n",
    "# this local version expects the data to be in code/tfrecords\n",
    "\n",
    "# sagemaker*.config\n",
    "#  uses S3 to move the data\n",
    "\n",
    "# !!! I haven't tested !!!\n",
    "\n",
    "# 20200122 - physical computer (Inspiron)\n",
    "#  using Jupyter (below) error: ModuleNotFoundError: No module named 'absl'\n",
    "#  but, ran fine from terminal\n",
    "#\n",
    "#  nvidia-smi\n",
    "#      NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. \n",
    "#      Make sure that the latest NVIDIA driver is installed and running.\n",
    "#  but it ran trained fine so CUDA was good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These parameters can be set, if ommitted, takes values from SM_CHANNEL_ {_MODEL_DIR, _TRAIN, _VAL}\n",
    "# --model_dir\n",
    "# --train\n",
    "# --val\n",
    "# note the config file\n",
    "\n",
    "! python train115.py \\\n",
    "  --pipeline_config_path=\"local_mobilenet_v1_ssd_security_retrain.config\" \\\n",
    "  --num_train_steps=\"10000\" \\\n",
    "  --num_eval_steps=\"1000\"  \\\n",
    "  --model_dir='model' \\\n",
    "  --train='tfrecords/train/train.tfrecord' \\\n",
    "  --val='tfrecords/val/val.tfrecord'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trained Model Output -- IMPORTANT\n",
    "Where did it go? - THERE IS A BIG DIFFERENCE BETWEEN LOCAL TRAIN AND HOSTED TRAIN -- important !!\n",
    "\n",
    "train*.py will put the output in code/model    This is true for local or SageMaker hosted trained.   In this case, you trained locally, so the output is in code/model  -- end of story.\n",
    "\n",
    "\n",
    "When you train with a SageMaker Hosted train, the output still goes to code/model -- HOWEVER - that is in a docker image (that you will never see).  Then it gets coped to S3.   Then the notebook (TrainModel_Step3_TrainingJob) pulls a model output from S3.   Then extracts the tarball to {PROJECT}/trained_model   SO AT THIS POINT THE OUTPUT IS IN A DIFFERENT LOCATION !!\n",
    "\n",
    "The convert graph script is pulling from {PROJECT}/trained_model (not the native code/model location).    The easiest solution (you will see below) is to copy the desired checkpoint graph to the {PROJECT}/trained_model location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 730720\r\n",
      "drwxr-xr-x  4 jay  jay       4096 Mar 26 10:37 .\r\n",
      "drwxr-xr-x 10 jay  jay       4096 Mar 26 06:09 ..\r\n",
      "-rw-r--r--  1 root root       277 Mar 26 10:33 checkpoint\r\n",
      "drwxr-xr-x  2 root root      4096 Mar 26 08:01 eval_0\r\n",
      "-rw-r--r--  1 root root  41422773 Mar 26 06:10 events.out.tfevents.1585175542.bf060c2b92f1\r\n",
      "-rw-r--r--  1 root root  41104985 Mar 26 07:46 events.out.tfevents.1585217492.bf060c2b92f1\r\n",
      "-rw-r--r--  1 root root  41122061 Mar 26 10:33 events.out.tfevents.1585223240.bf060c2b92f1\r\n",
      "drwxr-xr-x  3 root root      4096 Mar 26 10:37 export\r\n",
      "-rw-r--r--  1 root root  21828152 Mar 26 07:47 graph.pbtxt\r\n",
      "-rw-r--r--  1 root root 109220320 Mar 26 09:57 model.ckpt-68159.data-00000-of-00001\r\n",
      "-rw-r--r--  1 root root     42388 Mar 26 09:57 model.ckpt-68159.index\r\n",
      "-rw-r--r--  1 root root  11279875 Mar 26 09:57 model.ckpt-68159.meta\r\n",
      "-rw-r--r--  1 root root 109220320 Mar 26 10:07 model.ckpt-68516.data-00000-of-00001\r\n",
      "-rw-r--r--  1 root root     42388 Mar 26 10:07 model.ckpt-68516.index\r\n",
      "-rw-r--r--  1 root root  11279875 Mar 26 10:07 model.ckpt-68516.meta\r\n",
      "-rw-r--r--  1 root root 109220320 Mar 26 10:17 model.ckpt-68886.data-00000-of-00001\r\n",
      "-rw-r--r--  1 root root     42388 Mar 26 10:17 model.ckpt-68886.index\r\n",
      "-rw-r--r--  1 root root  11279875 Mar 26 10:17 model.ckpt-68886.meta\r\n",
      "-rw-r--r--  1 root root 109220320 Mar 26 10:27 model.ckpt-69371.data-00000-of-00001\r\n",
      "-rw-r--r--  1 root root     42388 Mar 26 10:27 model.ckpt-69371.index\r\n",
      "-rw-r--r--  1 root root  11279875 Mar 26 10:27 model.ckpt-69371.meta\r\n",
      "-rw-r--r--  1 root root 109220320 Mar 26 10:33 model.ckpt-70000.data-00000-of-00001\r\n",
      "-rw-r--r--  1 root root     42388 Mar 26 10:33 model.ckpt-70000.index\r\n",
      "-rw-r--r--  1 root root  11279875 Mar 26 10:33 model.ckpt-70000.meta\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir(CODE)   # this will be the training directory\n",
    "! ls -la  {MODEL_OUTPUT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "1. if you run for 500 steps, then rerun the exact process, it is going to restore /ckpt/checkpoints (ckpt-500) and then thinks it is done.  So, basically does nothing\n",
    "2. Don't delete ckpt/  (rm ckpt/*.*) WITHOUT removing ckpt/checkpoints/   The program is always checking that checkpoints subdirectory and trying to restore.  For exampmle, you delete ckpt/ but leave ckpt/checkpoints, it finds a reference to ckpt-500 but you just deleted it - so it aborts\n",
    "3. Always check your files & paths carefully - the error messages that get thrown with a missing file are not always clear - and my send you on a wild goose chase when in reality - it was just a missing file\n",
    "4. can't import nets - this is a PATH problem (models/research/slim needs to be in your path) - in the train.py program, it's programmatically added\n",
    "5. OOM when allocating tensor of shape [32,19,19,512] and type float\n",
    "\t [[{{node gradients/zeros_97}}]] -- go to the config file and change batch size to be smaller (e.g. 16)\n",
    "6. AttributeError: 'ParallelInterleaveDataset' object has no attribute '_flat_structure --- check your directories, like something didn't get installed correction (base model?  models/research stuff?  training data) -- seems to be a problem with the TF build from scratch;   use a pip install and this went away\n",
    "7. if you are mixing local ops and Docker runs - you may have messed up the ownership file outputs and checkpoints - try deleting everything and a new pull\n",
    "8. trains - then error:  TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a useable model\n",
    "At this point you have checkpoint files.   You need models (graphs).   There are many flavors:\n",
    "    - saved graph\n",
    "    - frozen graph\n",
    "    - TensorFlow Lite\n",
    "    - TensorRT\n",
    "    - EdgeTPU\n",
    "    \n",
    "The notebook:  TrainingJob_Step3_TrainingJob will show you how to convert a checkpoint file to a graph (frozen graph & tflite).   There is a bash file to do this.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/home/jay/projects/ssd-dag/trained_model/model.ckpt-70000.data-00000-of-00001\n",
      "/media/home/jay/projects/ssd-dag/trained_model/model.ckpt-70000.index\n",
      "/media/home/jay/projects/ssd-dag/trained_model/model.ckpt-70000.meta\n",
      "/media/home/jay/projects/ssd-dag/code/local_mobilenet_v1_ssd_security_retrain.config\n"
     ]
    }
   ],
   "source": [
    "# WAKE UP - make sure NUM_TRAINING_STEPS = the max number in the checkpoint files you listed above\n",
    "#  e.g. \n",
    "# ls model\n",
    "# -rw-rw-r--  1 ec2-user ec2-user 41116528 Jan 28 15:16 model.ckpt-6000.data-00000-of-00001\n",
    "# -rw-rw-r--  1 ec2-user ec2-user    27275 Jan 28 15:16 model.ckpt-6000.index\n",
    "# -rw-rw-r--  1 ec2-user {ec2-user  6987305 Jan 28 15:16 model.ckpt-6000.meta\n",
    "NUM_TRAINING_STEPS = 70000\n",
    "! cp {CODE}/model/*{NUM_TRAINING_STEPS}* {PROJECT}/trained_model\n",
    "! ls {PROJECT}/trained_model/*{NUM_TRAINING_STEPS}*\n",
    "\n",
    "# get the config from the train*.py parameters above\n",
    "PIPELINE_CONFIG = 'local_mobilenet_v1_ssd_security_retrain.config'\n",
    "# PIPELINE_CONFIG = 'local_mobilenet_v1_ssd_retrain.config'\n",
    "! ls {CODE}/{PIPELINE_CONFIG}\n",
    "\n",
    "# if you don't see your checkpoint in */trained_model/  STOP - and fix it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASKS_DIR=/media/home/jay/projects/ssd-dag/tasks\n",
      "***\n",
      "/media/home/jay/projects/ssd-dag/tflite_model\n",
      ":/media/home/jay/projects/ssd-dag/code/models/research/slim:/media/home/jay/projects/ssd-dag/code/models/research\n",
      "+ ckpt_number=0\n",
      "+ [[ 4 -gt 0 ]]\n",
      "+ case \"$1\" in\n",
      "+ ckpt_number=70000\n",
      "+ shift 2\n",
      "+ [[ 2 -gt 0 ]]\n",
      "+ case \"$1\" in\n",
      "+ pipeline_config=local_mobilenet_v1_ssd_security_retrain.config\n",
      "+ shift 2\n",
      "+ [[ 0 -gt 0 ]]\n",
      "+ rm /media/home/jay/projects/ssd-dag/tensorflow_model -rf\n",
      "+ rm /media/home/jay/projects/ssd-dag/tflite_model -rf\n",
      "+ echo '-- check for model checkpoint (the raw graph):,' , 70000\n",
      "-- check for model checkpoint (the raw graph):, , 70000\n",
      "+ ls /media/home/jay/projects/ssd-dag/trained_model/model.ckpt-70000.data-00000-of-00001 /media/home/jay/projects/ssd-dag/trained_model/model.ckpt-70000.index /media/home/jay/projects/ssd-dag/trained_model/model.ckpt-70000.meta\n",
      "/media/home/jay/projects/ssd-dag/trained_model/model.ckpt-70000.data-00000-of-00001\n",
      "/media/home/jay/projects/ssd-dag/trained_model/model.ckpt-70000.index\n",
      "/media/home/jay/projects/ssd-dag/trained_model/model.ckpt-70000.meta\n",
      "+ echo ' - - - CKPT ==> tensorflow frozen graph - - -'\n",
      " - - - CKPT ==> tensorflow frozen graph - - -\n",
      "+ python /media/home/jay/projects/ssd-dag/code/models/research/object_detection/export_inference_graph.py --input_type image_tensor --pipeline_config_path=/media/home/jay/projects/ssd-dag/code/local_mobilenet_v1_ssd_security_retrain.config ' ' --trained_checkpoint_prefix=/media/home/jay/projects/ssd-dag/trained_model/model.ckpt-70000 --output_directory=/media/home/jay/projects/ssd-dag/tensorflow_model\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0326 11:54:41.166338 140246823876416 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "W0326 11:54:41.235960 140246823876416 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0326 11:54:41.236552 140246823876416 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "W0326 11:54:41.282419 140246823876416 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0326 11:54:41.318314 140246823876416 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0326 11:54:41.319697 140246823876416 deprecation.py:323] From /media/home/jay/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "W0326 11:54:42.437401 140246823876416 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0326 11:54:42.444386 140246823876416 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0326 11:54:42.444460 140246823876416 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0326 11:54:42.468984 140246823876416 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0326 11:54:42.496439 140246823876416 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0326 11:54:42.520376 140246823876416 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0326 11:54:42.549071 140246823876416 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0326 11:54:42.573569 140246823876416 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0326 11:54:42.740524 140246823876416 deprecation.py:323] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "W0326 11:54:45.007598 140246823876416 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "W0326 11:54:45.007737 140246823876416 deprecation.py:323] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/builders/graph_rewriter_builder.py:41: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0326 11:54:45.009643 140246823876416 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/builders/graph_rewriter_builder.py:41: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\r\n",
      "I0326 11:54:45.761101 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\r\n",
      "I0326 11:54:45.761289 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\r\n",
      "I0326 11:54:45.761404 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\r\n",
      "I0326 11:54:45.761516 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\r\n",
      "I0326 11:54:45.761619 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\r\n",
      "I0326 11:54:45.761727 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\r\n",
      "I0326 11:54:45.761859 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\r\n",
      "I0326 11:54:45.761965 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\r\n",
      "I0326 11:54:45.762065 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\r\n",
      "I0326 11:54:45.762177 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\r\n",
      "I0326 11:54:45.762278 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\r\n",
      "I0326 11:54:45.762383 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\r\n",
      "I0326 11:54:45.762483 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\r\n",
      "I0326 11:54:45.762590 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\r\n",
      "I0326 11:54:45.762690 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\r\n",
      "I0326 11:54:45.762795 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\r\n",
      "I0326 11:54:45.762935 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\r\n",
      "I0326 11:54:45.763044 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\r\n",
      "I0326 11:54:45.763144 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\r\n",
      "I0326 11:54:45.763251 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\r\n",
      "I0326 11:54:45.763351 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\r\n",
      "I0326 11:54:45.763459 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\r\n",
      "I0326 11:54:45.763558 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\r\n",
      "I0326 11:54:45.763663 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\r\n",
      "I0326 11:54:45.763762 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\r\n",
      "I0326 11:54:45.763870 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\r\n",
      "I0326 11:54:45.763968 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\r\n",
      "I0326 11:54:45.764069 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\r\n",
      "I0326 11:54:45.764169 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\r\n",
      "I0326 11:54:45.764269 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\r\n",
      "I0326 11:54:45.764369 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\r\n",
      "I0326 11:54:45.764468 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\r\n",
      "I0326 11:54:45.764569 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\r\n",
      "I0326 11:54:45.764671 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\r\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\r\n",
      "I0326 11:54:45.764770 140246823876416 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\r\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\r\n",
      "Instructions for updating:\r\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\r\n",
      "W0326 11:54:45.766641 140246823876416 deprecation.py:323] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\r\n",
      "Instructions for updating:\r\n",
      "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\r\n",
      "WARNING:tensorflow:From /media/home/jay/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\r\n",
      "W0326 11:54:45.767430 140246823876416 deprecation.py:323] From /media/home/jay/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356 ops no flops stats due to incomplete shapes.\n",
      "Parsing Inputs...\n",
      "Incomplete shape.\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              0\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   name\n",
      "-account_type_regexes       _trainable_variables\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     params\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "Incomplete shape.\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "param: Number of parameters (in the Variable).\n",
      "\n",
      "Profile:\n",
      "node name | # parameters\n",
      "_TFProfRoot (--/6.79m params)\n",
      "  BoxPredictor_0 (--/146.21k params)\n",
      "    BoxPredictor_0/BoxEncodingPredictor (--/6.16k params)\n",
      "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
      "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n",
      "    BoxPredictor_0/ClassPredictor (--/140.05k params)\n",
      "      BoxPredictor_0/ClassPredictor/biases (273, 273/273 params)\n",
      "      BoxPredictor_0/ClassPredictor/weights (1x1x512x273, 139.78k/139.78k params)\n",
      "  BoxPredictor_1 (--/584.25k params)\n",
      "    BoxPredictor_1/BoxEncodingPredictor (--/24.60k params)\n",
      "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1024x24, 24.58k/24.58k params)\n",
      "    BoxPredictor_1/ClassPredictor (--/559.65k params)\n",
      "      BoxPredictor_1/ClassPredictor/biases (546, 546/546 params)\n",
      "      BoxPredictor_1/ClassPredictor/weights (1x1x1024x546, 559.10k/559.10k params)\n",
      "  BoxPredictor_2 (--/292.41k params)\n",
      "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
      "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
      "    BoxPredictor_2/ClassPredictor (--/280.10k params)\n",
      "      BoxPredictor_2/ClassPredictor/biases (546, 546/546 params)\n",
      "      BoxPredictor_2/ClassPredictor/weights (1x1x512x546, 279.55k/279.55k params)\n",
      "  BoxPredictor_3 (--/146.49k params)\n",
      "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
      "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
      "    BoxPredictor_3/ClassPredictor (--/140.32k params)\n",
      "      BoxPredictor_3/ClassPredictor/biases (546, 546/546 params)\n",
      "      BoxPredictor_3/ClassPredictor/weights (1x1x256x546, 139.78k/139.78k params)\n",
      "  BoxPredictor_4 (--/146.49k params)\n",
      "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
      "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
      "    BoxPredictor_4/ClassPredictor (--/140.32k params)\n",
      "      BoxPredictor_4/ClassPredictor/biases (546, 546/546 params)\n",
      "      BoxPredictor_4/ClassPredictor/weights (1x1x256x546, 139.78k/139.78k params)\n",
      "  BoxPredictor_5 (--/73.53k params)\n",
      "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
      "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
      "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
      "    BoxPredictor_5/ClassPredictor (--/70.43k params)\n",
      "      BoxPredictor_5/ClassPredictor/biases (546, 546/546 params)\n",
      "      BoxPredictor_5/ClassPredictor/weights (1x1x128x546, 69.89k/69.89k params)\n",
      "  FeatureExtractor (--/5.41m params)\n",
      "    FeatureExtractor/MobilenetV1 (--/5.41m params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_0 (--/864 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_0/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_0/weights (3x3x3x32, 864/864 params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_10_depthwise (--/4.61k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_10_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_10_pointwise (--/262.14k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_10_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_11_depthwise (--/4.61k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_11_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_11_pointwise (--/262.14k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_11_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_12_depthwise (--/4.61k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_12_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_12_pointwise (--/524.29k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_12_pointwise/weights (1x1x512x1024, 524.29k/524.29k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_depthwise (--/9.22k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_depthwise/depthwise_weights (3x3x1024x1, 9.22k/9.22k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise (--/1.05m params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise/weights (1x1x1024x1024, 1.05m/1.05m params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256 (--/262.14k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/weights (1x1x1024x256, 262.14k/262.14k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_1_depthwise (--/288 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_1_depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_1_pointwise (--/2.05k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_1_pointwise/weights (1x1x32x64, 2.05k/2.05k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_2_depthwise (--/576 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_2_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_2_pointwise (--/8.19k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_2_pointwise/weights (1x1x64x128, 8.19k/8.19k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_3_depthwise (--/1.15k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_3_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_3_pointwise (--/16.38k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_3_pointwise/weights (1x1x128x128, 16.38k/16.38k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_4_depthwise (--/1.15k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_4_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_4_pointwise (--/32.77k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_4_pointwise/weights (1x1x128x256, 32.77k/32.77k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_5_depthwise (--/2.30k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_5_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_5_pointwise (--/65.54k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_5_pointwise/weights (1x1x256x256, 65.54k/65.54k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_6_depthwise (--/2.30k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_6_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_6_pointwise (--/131.07k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_6_pointwise/weights (1x1x256x512, 131.07k/131.07k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_7_depthwise (--/4.61k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_7_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_7_pointwise (--/262.14k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_7_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_8_depthwise (--/4.61k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_8_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_8_pointwise (--/262.14k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_8_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_9_depthwise (--/4.61k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_9_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n",
      "      FeatureExtractor/MobilenetV1/Conv2d_9_pointwise (--/262.14k params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/BatchNorm (--/0 params)\n",
      "        FeatureExtractor/MobilenetV1/Conv2d_9_pointwise/weights (1x1x512x512, 262.14k/262.14k params)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356 ops no flops stats due to incomplete shapes.\n",
      "Parsing Inputs...\n",
      "Incomplete shape.\n",
      "\n",
      "=========================Options=============================\n",
      "-max_depth                  10000\n",
      "-min_bytes                  0\n",
      "-min_peak_bytes             0\n",
      "-min_residual_bytes         0\n",
      "-min_output_bytes           0\n",
      "-min_micros                 0\n",
      "-min_accelerator_micros     0\n",
      "-min_cpu_micros             0\n",
      "-min_params                 0\n",
      "-min_float_ops              1\n",
      "-min_occurrence             0\n",
      "-step                       -1\n",
      "-order_by                   float_ops\n",
      "-account_type_regexes       .*\n",
      "-start_name_regexes         .*\n",
      "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
      "-show_name_regexes          .*\n",
      "-hide_name_regexes          \n",
      "-account_displayed_op_only  true\n",
      "-select                     float_ops\n",
      "-output                     stdout:\n",
      "\n",
      "==================Model Analysis Report======================\n",
      "Incomplete shape.\n",
      "\n",
      "Doc:\n",
      "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
      "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
      "\n",
      "Profile:\n",
      "node name | # float_ops\n",
      "_TFProfRoot (--/5.42m flops)\n",
      "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/mul_fold (1.18m/1.18m flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/mul_fold (1.05m/1.05m flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/mul_fold (524.29k/524.29k flops)\n",
      "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n",
      "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/mul_fold (294.91k/294.91k flops)\n",
      "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/mul_fold (262.14k/262.14k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/mul_fold (262.14k/262.14k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/mul_fold (262.14k/262.14k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/mul_fold (262.14k/262.14k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/mul_fold (262.14k/262.14k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/mul_fold (262.14k/262.14k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/mul_fold (131.07k/131.07k flops)\n",
      "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/mul_fold (73.73k/73.73k flops)\n",
      "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/mul_fold (65.54k/65.54k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/mul_fold (65.54k/65.54k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/mul_fold (32.77k/32.77k flops)\n",
      "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/mul_fold (32.77k/32.77k flops)\n",
      "  FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/mul_fold (16.38k/16.38k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/mul_fold (16.38k/16.38k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/mul_fold (9.22k/9.22k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/mul_fold (8.19k/8.19k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/mul_fold (4.61k/4.61k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/mul_fold (4.61k/4.61k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/mul_fold (4.61k/4.61k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/mul_fold (4.61k/4.61k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/mul_fold (4.61k/4.61k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/mul_fold (4.61k/4.61k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/mul_fold (2.30k/2.30k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/mul_fold (2.30k/2.30k flops)\n",
      "  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n",
      "  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n",
      "  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/mul_fold (2.05k/2.05k flops)\n",
      "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
      "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
      "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/mul_fold (1.15k/1.15k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/mul_fold (1.15k/1.15k flops)\n",
      "  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/mul_fold (864/864 flops)\n",
      "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/mul_fold (576/576 flops)\n",
      "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
      "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
      "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
      "  FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/mul_fold (288/288 flops)\n",
      "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
      "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
      "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
      "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
      "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
      "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
      "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
      "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
      "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
      "  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n",
      "  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n",
      "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
      "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
      "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
      "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
      "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
      "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
      "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
      "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
      "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_176 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_29 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_28 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_173 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_27 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_26 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_25 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_24 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_23 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_22 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_21 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_20 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_19 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_18 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_179 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_174 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_178 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_175 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_177 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_49 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_48 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_47 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_46 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_45 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_44 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_43 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_42 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_41 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_40 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_30 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_39 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_38 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_37 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_36 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_35 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_34 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_33 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_32 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_31 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_141 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_138 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_139 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_155 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_154 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_153 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_152 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_151 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_150 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_14 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_140 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_137 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_15 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_149 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_148 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_147 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_146 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_145 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_135 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_142 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_144 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_143 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_162 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_171 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_170 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_17 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_169 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_168 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_167 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_166 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_165 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_164 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_163 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_172 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_161 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_160 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_16 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_159 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_158 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_157 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_156 (1/1 flops)\n",
      "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_136 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_99 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_98 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_97 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_96 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_95 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_94 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_93 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_92 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_91 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_90 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
      "  Preprocessor/map/while/Less (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_60 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_7 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_69 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_68 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_67 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_66 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_65 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_64 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_63 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_62 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_61 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_70 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_6 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_59 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_58 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_57 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_56 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_55 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_54 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_53 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_52 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_51 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_8 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_89 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_88 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_87 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_86 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_85 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_84 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_83 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_82 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_81 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_80 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_50 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_79 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_78 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_77 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_76 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_75 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_74 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_73 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_72 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_71 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_21 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_30 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_29 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_28 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_27 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_26 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_25 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_24 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_23 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_22 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_31 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_20 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_19 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_18 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_17 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_16 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_15 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_14 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_13 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_12 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_41 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_50 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_5 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_49 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_48 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_47 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_46 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_45 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_44 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_43 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_42 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_11 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_40 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_4 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_39 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_38 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_37 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_36 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_35 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_34 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_33 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_32 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_10 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_51 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
      "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_105 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_114 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_113 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_112 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_111 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_110 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_11 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_109 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_108 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_107 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_106 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_115 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_104 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_103 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_102 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_101 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_100 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_10 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_124 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_133 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_132 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_131 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_130 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_13 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_129 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_128 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_127 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_126 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_125 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_90 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_123 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_122 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_121 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_120 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_12 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_119 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_118 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_117 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_116 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_61 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_70 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_7 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_69 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_68 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_67 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_66 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_65 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_64 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_63 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_62 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_71 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_60 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_6 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_59 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_58 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_57 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_56 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_55 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_54 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_53 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_52 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_80 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_9 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_89 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_88 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_87 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_86 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_85 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_84 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_83 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_82 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_81 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_134 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_8 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_79 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_78 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_77 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_76 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_75 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_74 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_73 (1/1 flops)\n",
      "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_72 (1/1 flops)\n",
      "\n",
      "======================End of Report==========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0326 11:54:47.639828 140246823876416 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0326 11:54:48.762277 140246823876416 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2020-03-26 11:54:48.785697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-03-26 11:54:48.809000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:54:48.809319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-03-26 11:54:48.811333: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-03-26 11:54:48.813927: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-03-26 11:54:48.815089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-03-26 11:54:48.816292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-03-26 11:54:48.818801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-03-26 11:54:48.820393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-03-26 11:54:48.824886: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-03-26 11:54:48.824972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:54:48.825291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:54:48.825551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2020-03-26 11:54:48.825774: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-03-26 11:54:48.930427: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3696000000 Hz\n",
      "2020-03-26 11:54:48.933123: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55793cc2aec0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-03-26 11:54:48.933190: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-03-26 11:54:49.023792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:54:49.024151: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55793cd4ec00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-03-26 11:54:49.024166: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1\n",
      "2020-03-26 11:54:49.024273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:54:49.024538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-03-26 11:54:49.024566: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-03-26 11:54:49.024578: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-03-26 11:54:49.024589: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-03-26 11:54:49.024600: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-03-26 11:54:49.024611: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-03-26 11:54:49.024622: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-03-26 11:54:49.024633: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-03-26 11:54:49.024664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:54:49.024942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:54:49.025195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2020-03-26 11:54:49.031189: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-03-26 11:54:49.031679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-26 11:54:49.031691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2020-03-26 11:54:49.031698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2020-03-26 11:54:49.032170: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:54:49.032434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:54:49.032696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6621 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "INFO:tensorflow:Restoring parameters from /media/home/jay/projects/ssd-dag/trained_model/model.ckpt-70000\n",
      "I0326 11:54:49.034331 140246823876416 saver.py:1284] Restoring parameters from /media/home/jay/projects/ssd-dag/trained_model/model.ckpt-70000\n",
      "WARNING:tensorflow:From /media/home/jay/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W0326 11:54:59.705217 140246823876416 deprecation.py:323] From /media/home/jay/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 11:55:00.722531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:00.722740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-03-26 11:55:00.722769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-03-26 11:55:00.722779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-03-26 11:55:00.722786: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-03-26 11:55:00.722794: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-03-26 11:55:00.722802: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-03-26 11:55:00.722810: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-03-26 11:55:00.722818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-03-26 11:55:00.722852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:00.723046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:00.723212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2020-03-26 11:55:00.723230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-26 11:55:00.723235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2020-03-26 11:55:00.723240: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2020-03-26 11:55:00.723290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:00.723483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:00.723656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6621 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "INFO:tensorflow:Restoring parameters from /media/home/jay/projects/ssd-dag/trained_model/model.ckpt-70000\n",
      "I0326 11:55:00.724273 140246823876416 saver.py:1284] Restoring parameters from /media/home/jay/projects/ssd-dag/trained_model/model.ckpt-70000\n",
      "WARNING:tensorflow:From /media/home/jay/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "W0326 11:55:01.646306 140246823876416 deprecation.py:323] From /media/home/jay/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /media/home/jay/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "W0326 11:55:01.646446 140246823876416 deprecation.py:323] From /media/home/jay/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 387 variables.\n",
      "I0326 11:55:02.170839 140246823876416 graph_util_impl.py:334] Froze 387 variables.\n",
      "INFO:tensorflow:Converted 387 variables to const ops.\n",
      "I0326 11:55:02.262253 140246823876416 graph_util_impl.py:394] Converted 387 variables to const ops.\n",
      "2020-03-26 11:55:02.443449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:02.443678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-03-26 11:55:02.443713: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-03-26 11:55:02.443724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-03-26 11:55:02.443735: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-03-26 11:55:02.443745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-03-26 11:55:02.443755: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-03-26 11:55:02.443765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-03-26 11:55:02.443776: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-03-26 11:55:02.444370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:02.445279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:02.445444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2020-03-26 11:55:02.445465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-26 11:55:02.445472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2020-03-26 11:55:02.445478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2020-03-26 11:55:02.445535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:02.445846: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:02.446014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6621 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
      "\n",
      "W0326 11:55:03.206175 140246823876416 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "W0326 11:55:03.206419 140246823876416 deprecation.py:323] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
      "\n",
      "W0326 11:55:03.206665 140246823876416 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
      "\n",
      "W0326 11:55:03.206746 140246823876416 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
      "\n",
      "W0326 11:55:03.206863 140246823876416 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\n",
      "W0326 11:55:03.206928 140246823876416 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
      "\n",
      "INFO:tensorflow:No assets to save.\n",
      "I0326 11:55:03.207072 140246823876416 builder_impl.py:640] No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "I0326 11:55:03.207117 140246823876416 builder_impl.py:460] No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: /media/home/jay/projects/ssd-dag/tensorflow_model/saved_model/saved_model.pb\n",
      "I0326 11:55:03.709092 140246823876416 builder_impl.py:425] SavedModel written to: /media/home/jay/projects/ssd-dag/tensorflow_model/saved_model/saved_model.pb\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0326 11:55:03.755578 140246823876416 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "INFO:tensorflow:Writing pipeline config file to /media/home/jay/projects/ssd-dag/tensorflow_model/pipeline.config\n",
      "I0326 11:55:03.755696 140246823876416 config_util.py:190] Writing pipeline config file to /media/home/jay/projects/ssd-dag/tensorflow_model/pipeline.config\n",
      "+ echo ' - - - CKPT ==> tflite frozen graph - - -'\n",
      " - - - CKPT ==> tflite frozen graph - - -\n",
      "+ python /media/home/jay/projects/ssd-dag/code/models/research/object_detection/export_tflite_ssd_graph.py --pipeline_config_path=/media/home/jay/projects/ssd-dag/code/local_mobilenet_v1_ssd_security_retrain.config --trained_checkpoint_prefix=/media/home/jay/projects/ssd-dag/trained_model/model.ckpt-70000 --output_directory=/media/home/jay/projects/ssd-dag/tflite_model --add_postprocessing_op=true\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/export_tflite_ssd_graph.py:143: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/export_tflite_ssd_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0326 11:55:06.410422 140289241147200 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/export_tflite_ssd_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/export_tflite_ssd_graph_lib.py:193: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "W0326 11:55:06.412958 140289241147200 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/export_tflite_ssd_graph_lib.py:193: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/export_tflite_ssd_graph_lib.py:237: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0326 11:55:06.413116 140289241147200 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/export_tflite_ssd_graph_lib.py:237: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0326 11:55:06.414859 140289241147200 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0326 11:55:06.415803 140289241147200 deprecation.py:323] From /media/home/jay/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "W0326 11:55:07.310171 140289241147200 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "W0326 11:55:07.316752 140289241147200 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0326 11:55:07.316849 140289241147200 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0326 11:55:07.335688 140289241147200 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0326 11:55:07.354908 140289241147200 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0326 11:55:07.373890 140289241147200 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0326 11:55:07.392766 140289241147200 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
      "I0326 11:55:07.412030 140289241147200 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/export_tflite_ssd_graph_lib.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0326 11:55:07.439229 140289241147200 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/export_tflite_ssd_graph_lib.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2020-03-26 11:55:07.439915: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-03-26 11:55:07.455397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:07.455734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-03-26 11:55:07.455859: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-03-26 11:55:07.456658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-03-26 11:55:07.457346: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-03-26 11:55:07.457503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-03-26 11:55:07.458494: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-03-26 11:55:07.459209: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-03-26 11:55:07.461378: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-03-26 11:55:07.461453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:07.461932: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:07.462214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2020-03-26 11:55:07.462459: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-03-26 11:55:07.486300: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3696000000 Hz\n",
      "2020-03-26 11:55:07.486761: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56345ddafd30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-03-26 11:55:07.486777: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 11:55:07.543449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:07.543818: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56345de42660 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-03-26 11:55:07.543832: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1\n",
      "2020-03-26 11:55:07.543944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:07.544235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-03-26 11:55:07.544263: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-03-26 11:55:07.544278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-03-26 11:55:07.544291: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-03-26 11:55:07.544300: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-03-26 11:55:07.544309: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-03-26 11:55:07.544317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-03-26 11:55:07.544326: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-03-26 11:55:07.544358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:07.544661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:07.545348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2020-03-26 11:55:07.545380: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-03-26 11:55:07.545852: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-26 11:55:07.545862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2020-03-26 11:55:07.545866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2020-03-26 11:55:07.545930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:07.546199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:07.546444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6621 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/export_tflite_ssd_graph_lib.py:267: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "W0326 11:55:08.237881 140289241147200 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/export_tflite_ssd_graph_lib.py:267: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/builders/graph_rewriter_builder.py:41: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0326 11:55:08.246776 140289241147200 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/builders/graph_rewriter_builder.py:41: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n",
      "I0326 11:55:08.846509 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_0/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n",
      "I0326 11:55:08.846708 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_depthwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n",
      "I0326 11:55:08.846824 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_1_pointwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n",
      "I0326 11:55:08.846942 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_depthwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n",
      "I0326 11:55:08.847050 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_2_pointwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n",
      "I0326 11:55:08.847158 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_depthwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n",
      "I0326 11:55:08.847259 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_3_pointwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n",
      "I0326 11:55:08.847366 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_depthwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n",
      "I0326 11:55:08.847485 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_4_pointwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n",
      "I0326 11:55:08.847681 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_depthwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n",
      "I0326 11:55:08.847830 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_5_pointwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n",
      "I0326 11:55:08.847937 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_depthwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n",
      "I0326 11:55:08.848039 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_6_pointwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n",
      "I0326 11:55:08.848146 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_depthwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n",
      "I0326 11:55:08.848248 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_7_pointwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n",
      "I0326 11:55:08.848354 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_depthwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n",
      "I0326 11:55:08.848456 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_8_pointwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n",
      "I0326 11:55:08.848563 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_depthwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n",
      "I0326 11:55:08.848666 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_9_pointwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n",
      "I0326 11:55:08.848774 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_depthwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n",
      "I0326 11:55:08.848875 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_10_pointwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n",
      "I0326 11:55:08.848981 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_depthwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n",
      "I0326 11:55:08.849081 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_11_pointwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n",
      "I0326 11:55:08.849188 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_depthwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n",
      "I0326 11:55:08.849291 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_12_pointwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n",
      "I0326 11:55:08.849396 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_depthwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n",
      "I0326 11:55:08.849497 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/MobilenetV1/Conv2d_13_pointwise/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\n",
      "I0326 11:55:08.849597 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_2_1x1_256/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\n",
      "I0326 11:55:08.849699 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_2_3x3_s2_512/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\n",
      "I0326 11:55:08.849829 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_3_1x1_128/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\n",
      "I0326 11:55:08.849928 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_3_3x3_s2_256/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\n",
      "I0326 11:55:08.850028 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_4_1x1_128/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\n",
      "I0326 11:55:08.850131 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_4_3x3_s2_256/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\n",
      "I0326 11:55:08.850232 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_1_Conv2d_5_1x1_64/add_fold\n",
      "INFO:tensorflow:Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\n",
      "I0326 11:55:08.850332 140289241147200 quantize.py:299] Skipping quant after FeatureExtractor/MobilenetV1/Conv2d_13_pointwise_2_Conv2d_5_3x3_s2_128/add_fold\n",
      "WARNING:tensorflow:From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/export_tflite_ssd_graph_lib.py:292: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "W0326 11:55:08.851421 140289241147200 module_wrapper.py:139] From /media/home/jay/projects/ssd-dag/code/models/research/object_detection/export_tflite_ssd_graph_lib.py:292: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /media/home/jay/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "W0326 11:55:09.049654 140289241147200 deprecation.py:323] From /media/home/jay/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "2020-03-26 11:55:09.375775: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:09.375986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-03-26 11:55:09.376016: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-03-26 11:55:09.376025: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-03-26 11:55:09.376032: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-03-26 11:55:09.376040: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-03-26 11:55:09.376047: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-03-26 11:55:09.376055: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-03-26 11:55:09.376063: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-03-26 11:55:09.376097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:09.376290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:09.376456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2020-03-26 11:55:09.376473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-26 11:55:09.376478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2020-03-26 11:55:09.376482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2020-03-26 11:55:09.376531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:09.376724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:09.376899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6621 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "INFO:tensorflow:Restoring parameters from /media/home/jay/projects/ssd-dag/trained_model/model.ckpt-70000\n",
      "I0326 11:55:09.377526 140289241147200 saver.py:1284] Restoring parameters from /media/home/jay/projects/ssd-dag/trained_model/model.ckpt-70000\n",
      "WARNING:tensorflow:From /media/home/jay/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "W0326 11:55:09.875977 140289241147200 deprecation.py:323] From /media/home/jay/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /media/home/jay/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "W0326 11:55:09.876100 140289241147200 deprecation.py:323] From /media/home/jay/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 387 variables.\n",
      "I0326 11:55:10.133485 140289241147200 graph_util_impl.py:334] Froze 387 variables.\n",
      "INFO:tensorflow:Converted 387 variables to const ops.\n",
      "I0326 11:55:10.169326 140289241147200 graph_util_impl.py:394] Converted 387 variables to const ops.\n",
      "2020-03-26 11:55:10.244157: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes\n",
      "+ echo ' - - - - - - - -'\n",
      " - - - - - - - -\n",
      "+ echo INPUT_TENORS\n",
      "INPUT_TENORS\n",
      "+ echo ' - - - tflite frozen graph ==> *.tflite - - - '\n",
      " - - - tflite frozen graph ==> *.tflite - - - \n",
      "+ tflite_convert --output_file=/media/home/jay/projects/ssd-dag/tflite_model/output_tflite_graph.tflite --graph_def_file=/media/home/jay/projects/ssd-dag/tflite_model/tflite_graph.pb --inference_type=QUANTIZED_UINT8 --input_arrays=normalized_input_image_tensor --output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 --mean_values=128 --std_dev_values=128 --input_shapes=1,300,300,3 --change_concat_input_ranges=false --allow_nudging_weights_to_use_fast_gemm_kernel=true --allow_custom_ops\n",
      "2020-03-26 11:55:11.872632: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-03-26 11:55:11.888790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:11.889087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-03-26 11:55:11.889206: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-03-26 11:55:11.889992: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-03-26 11:55:11.890717: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-03-26 11:55:11.890871: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-03-26 11:55:11.891788: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-03-26 11:55:11.892477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-03-26 11:55:11.894666: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-03-26 11:55:11.894731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:11.895130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:11.895371: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2020-03-26 11:55:11.895606: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-26 11:55:11.918409: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3696000000 Hz\n",
      "2020-03-26 11:55:11.919275: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d35bb6b320 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-03-26 11:55:11.919288: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-03-26 11:55:11.974538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:11.975061: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d35bbfdc00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-03-26 11:55:11.975074: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1\n",
      "2020-03-26 11:55:11.975188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:11.975457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-03-26 11:55:11.975487: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-03-26 11:55:11.975497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-03-26 11:55:11.975510: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-03-26 11:55:11.975524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-03-26 11:55:11.975534: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-03-26 11:55:11.975542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-03-26 11:55:11.975549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-03-26 11:55:11.975588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:11.975865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:11.976119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2020-03-26 11:55:11.976148: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-03-26 11:55:11.976633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-26 11:55:11.976644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2020-03-26 11:55:11.976651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2020-03-26 11:55:11.976716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:11.977027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-03-26 11:55:11.977301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6621 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "+ echo 'TFLite graph generated at /media/home/jay/projects/ssd-dag/tflite_model/output_tflite_graph.tflite'\n",
      "TFLite graph generated at /media/home/jay/projects/ssd-dag/tflite_model/output_tflite_graph.tflite\n"
     ]
    }
   ],
   "source": [
    "# convert checkpoint is a task script - located in the tasks/ directory\n",
    "os.chdir(TASKS)  \n",
    "! ./convert_checkpoint_to_edgetpu_tflite.sh --checkpoint_num {NUM_TRAINING_STEPS} --pipeline_config {PIPELINE_CONFIG}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 59040\r\n",
      "-rw-r--r-- 1 jay jay       77 Mar 26 11:54 checkpoint\r\n",
      "-rw-r--r-- 1 jay jay 29536515 Mar 26 11:55 frozen_inference_graph.pb\r\n",
      "-rw-r--r-- 1 jay jay 27381492 Mar 26 11:54 model.ckpt.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 jay jay    14948 Mar 26 11:54 model.ckpt.index\r\n",
      "-rw-r--r-- 1 jay jay  3500465 Mar 26 11:54 model.ckpt.meta\r\n",
      "-rw-r--r-- 1 jay jay     5103 Mar 26 11:55 pipeline.config\r\n",
      "drwxr-xr-x 3 jay jay     4096 Mar 26 11:55 saved_model\r\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow FROZEN GRAPH\n",
    "! ls {PROJECT}/tensorflow_model -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 111216\r\n",
      "-rw-r--r-- 1 jay jay  6898968 Mar 26 11:55 output_tflite_graph.tflite\r\n",
      "-rw-r--r-- 1 jay jay 27693983 Mar 26 11:55 tflite_graph.pb\r\n",
      "-rw-r--r-- 1 jay jay 79284971 Mar 26 11:55 tflite_graph.pbtxt\r\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow Lite model\n",
    "! ls {PROJECT}/tflite_model -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Security\n",
    "If you are working on the security project,   you need to:  \n",
    "put thye output_tflight_graph.tflite file in:  camera-api/model/  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the tflite model over to camera-api/model\n",
    "! cp  {PROJECT}/tflite_model/output_tflite_graph.tflite {CAMERA_API_MODEL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 134004\r\n",
      "26740 -rw-r--r-- 1 jay jay 27381492 Mar 24 15:43 model.ckpt.data-00000-of-00001\r\n",
      "   16 -rw-r--r-- 1 jay jay    14948 Mar 24 15:43 model.ckpt.index\r\n",
      " 3420 -rw-r--r-- 1 jay jay  3500465 Mar 24 15:43 model.ckpt.meta\r\n",
      "    8 -rw-r--r-- 1 jay jay     4469 Oct  4 09:22 pipeline.config\r\n",
      "27044 -rw-r--r-- 1 jay jay 27692743 Oct  4 09:22 tflite_graph.pb\r\n",
      "76776 -rw-r--r-- 1 jay jay 78617899 Oct  4 09:22 tflite_graph.pbtxt\r\n"
     ]
    }
   ],
   "source": [
    "# just checking ...\n",
    "! ls -ls {CODE}/ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the (converted?  frozen?) ckpt to the starting point\n",
    "# NOW you can re-train on top of it\n",
    "! cp {PROJECT}/tensorflow_model/model.ckpt.* {CODE}/ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-29 19:45:19 jmduff.data\r\n",
      "2018-08-23 21:11:49 jmduff.glacier\r\n",
      "2020-03-24 15:53:56 jmduff.security-system\r\n",
      "2020-01-20 15:49:21 jmduff.software\r\n",
      "2018-04-19 20:22:47 jmduff.xps14z\r\n"
     ]
    }
   ],
   "source": [
    "# backup\n",
    "! aws s3 ls --profile=jmduff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../tensorflow_model/checkpoint to s3://jmduff.security-system/model/20200326/checkpoint\n",
      "upload: ../tensorflow_model/model.ckpt.index to s3://jmduff.security-system/model/20200326/model.ckpt.index\n",
      "upload: ../tensorflow_model/pipeline.config to s3://jmduff.security-system/model/20200326/pipeline.config\n",
      "upload: ../tensorflow_model/model.ckpt.meta to s3://jmduff.security-system/model/20200326/model.ckpt.meta\n",
      "upload: ../tensorflow_model/frozen_inference_graph.pb to s3://jmduff.security-system/model/20200326/frozen_inference_graph.pb\n",
      "upload: ../tensorflow_model/model.ckpt.data-00000-of-00001 to s3://jmduff.security-system/model/20200326/model.ckpt.data-00000-of-00001\n",
      "upload: ../tensorflow_model/saved_model/saved_model.pb to s3://jmduff.security-system/model/20200326/saved_model/saved_model.pb\n",
      "upload: ../tflite_model/output_tflite_graph.tflite to s3://jmduff.security-system/model/20200326/output_tflite_graph.tflite\n",
      "upload: ../tflite_model/tflite_graph.pb to s3://jmduff.security-system/model/20200326/tflite_graph.pb\n",
      "upload: ../tflite_model/tflite_graph.pbtxt to s3://jmduff.security-system/model/20200326/tflite_graph.pbtxt\n"
     ]
    }
   ],
   "source": [
    "MODEL_DATE = '20200326'\n",
    "! aws s3 cp {PROJECT}/tensorflow_model s3://jmduff.security-system/model/{MODEL_DATE}/ --exclude='*.*' --include='*.*' --recursive --profile=jmduff\n",
    "! aws s3 cp {PROJECT}/tflite_model s3://jmduff.security-system/model/{MODEL_DATE}/ --exclude='*.*' --include='*.*' --recursive --profile=jmduff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/home/jay/projects/ssd-dag\r\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/media/home/jay/projects/ssd-dag')\n",
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf115)",
   "language": "python",
   "name": "tf115"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
