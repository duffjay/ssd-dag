{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "#### tensorflow_p36 environment\n",
    "\n",
    "There are several ways to run this code\n",
    "- on a SageMaker notebook (the original intent)\n",
    "- on a physical machine with a well configured dev environment\n",
    "- on a physical machine using a Docker (grilledclub/cuda-100-tf114:*)\n",
    "\n",
    "## Step 1 - Develop a train.py script\n",
    "\n",
    "This is SageMaker Script Mode.   This is relatively new and much easier than the original SageMaker design.   You need to develop a train.py program that will:\n",
    "1. run locally - that means it will run on the local resources\n",
    "2. then you will test it locally with a Docker test\n",
    "\n",
    "If it runs in these tests, then it will/should run fine when you create a SageMaker Training job.   THIS IS THE CORRECT WAY TO USE SAGEMAKER.   Don't get confused - running jobs on the local SageMaker server isn't really what it was designed for.  It is designed to take your program and send it to outside resouces (using a Docker container)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker is at 1.15\n",
    "# - kernel = conda_python3\n",
    "# ! pip install tensorflow-gpu==1.14\n",
    "#\n",
    "# - kernel = conda_tensorflow_p36\n",
    "#   1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\r\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\r\n",
      "Cuda compilation tools, release 10.1, V10.1.243\r\n"
     ]
    }
   ],
   "source": [
    "# currently CUDA 10.0\n",
    "! nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nvidia-smi\n",
    "this will show you how much memory is available in the GPU.   This is important if you start getting OOM (out of memory) errors.\n",
    "\n",
    "SageMaker p2.xlarge == 10+ GB  \n",
    "Note what is available.\n",
    "\n",
    "you can run (at a terminal)    \n",
    "  $ nvidia-smi -l 1   \n",
    "to see the GPU being used during training.  On SageMaker, you'll see the GPU is about 50% busy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 26 21:27:28 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.82       Driver Version: 440.82       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   32C    P8     1W / 260W |    251MiB / 11011MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      1453      G   /usr/lib/xorg/Xorg                            40MiB |\n",
      "|    0      1516      G   /usr/bin/gnome-shell                          53MiB |\n",
      "|    0      4244      G   /usr/lib/xorg/Xorg                            99MiB |\n",
      "|    0      4377      G   /usr/bin/gnome-shell                          53MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi\n",
    "! nvcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your GPU\n",
    "this should verify your GPU is correct\n",
    "\n",
    "## WARNING\n",
    "this is a good test but...  \n",
    "If you run it, it may not release  the GPU memory.   I didn't figure this out fully.   When I ran it, I would get an OOM error when the model started the training cycle - even with super small batch size.   So, something is up here.   You could play around and try stopping the notebook - check nvidia-smi to verify it released the GPU RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print (sess.run(c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MobileNet Model\n",
    "Why use a MobileNet Model?  Because the end objective is a lightweight model - one that will run on a Googl Coral TPU.    This requires a quantized model (int8 - not float32).  And, you get there from a TensorFlow Lite model.  The recommended path is to start with a model structure that you know is compatible (MobileNet) then retrain on top of it.  \n",
    "1. We pull the MobileNet v1 (there is a v2 that we aren't using) trained on COCO images\n",
    "2. We train on top of it (xfer learning) with our CFA Products\n",
    "3. That generates a TensorFlow Lite model (.tflite)\n",
    "4. We will later conver .tflite to an edge TPU model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project directory: /home/train/projects/ssd-dag\n",
      "code directory: /home/train/projects/ssd-dag/code\n",
      "task directory: /home/train/projects/ssd-dag/tasks\n"
     ]
    }
   ],
   "source": [
    "# -- original EA DataScience SB\n",
    "# S3_TFRECORDS_PATH = \"s3://cfa-eadatasciencesb-sagemaker/datasets/cfa_products/tfrecords/\"\n",
    "# TFRECORDS_TARBALL = \"20190718_tfrecords.tar.gz\"\n",
    "# S3_TFRECORDS_PATH = \"s3://cfa-eadatasciencesb-sagemaker/datasets/security/tfrecords/\"\n",
    "# TFRECORDS_TARBALL = \"20200323_tfrecords.tar.gz\"\n",
    "\n",
    "# Security - Local using jmduff AWS\n",
    "S3_TFRECORDS_PATH = \"s3://jmduff.security-system/tfrecords/\"\n",
    "TFRECORDS_TARBALL = \"20200426_tfrecords.tar.gz\"\n",
    "\n",
    "S3_MODEL_PATH = \"s3://jmduff.security-system/model/base_mobilenet/\"\n",
    "# base model - starting point that we train on top of\n",
    "BASE_MODEL_FOLDER = \"20180718_coco14_mobilenet_v1_ssd300_quantized\"\n",
    "\n",
    "# our CFA model\n",
    "# note the COINCIDENCE - 2018-0718 vs 2019-0718, don't let this confuse you!\n",
    "CFA_MODEL_FOLDER = \"20190718_cfa_prod_mobilenet_v1_ssd300/\"\n",
    "\n",
    "# project directories\n",
    "PROJECT = os.getcwd()\n",
    "CODE = os.path.join(PROJECT, \"code\")\n",
    "TASKS = os.path.join(PROJECT, \"tasks\")\n",
    "MODEL_OUTPUT = os.path.join(CODE, 'model')\n",
    "\n",
    "print (\"project directory:\", PROJECT)\n",
    "print (\"code directory:\", CODE)\n",
    "print (\"task directory:\", TASKS)\n",
    "\n",
    "# Link to Security Project\n",
    "CAMERA_API = os.path.abspath(os.path.join(PROJECT, '..', 'camera-api'))\n",
    "CAMERA_API_MODEL = os.path.join(CAMERA_API, 'model')\n",
    "\n",
    "MODEL_DATE = '20200426'\n",
    "USER = 'train'  # linux user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the updated label map file from camera-api project\n",
    "! cp {CAMERA_API_MODEL}/security_label_map.pbtxt {CODE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data - 1x only\n",
    "\n",
    "Get the data from s3.  You only need to pull the data once - unless of course you update it.  you'll need to pass a directory into the training job\n",
    "\n",
    "## Options: S3 or USB drive\n",
    "\n",
    "### Option 1: S3 & Sagemaker\n",
    "\n",
    "####  NOTE\n",
    "still unclear if data is in the Docker or passed in with the SageMaker job  \n",
    "TODO - figure this out, it's faster to NOT put it in the Docker (code/tfrecords), it just makes the Docker step slower.   the AWS fetch when the Docker starts is much faster\n",
    "\n",
    "### Option 2:  USB Drive\n",
    "mount the drive first, do it from command line - here are the commands:\n",
    "\n",
    "`sudo fdisk -l | grep dev/sd`  \n",
    "/dev/sdb1        2048 976770112 976768065 465.8G 83 Linux  \n",
    "\n",
    "`sudo mount /dev/sdb1 /media/train/ssd-usb0`  \n",
    "`sudo chown train:train /media/train/ssd-usb0`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical or Docker\n",
    "# you can run the script\n",
    "# $ cd /task\n",
    "\n",
    "# check the Globals values in the script\n",
    "# $ bash local_get_s3_files.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1 - from s3 - kinda slow\n",
    "# SAGEMAKER\n",
    "#  you're in top project directory\n",
    "s3_tfrecords = os.path.join(S3_TFRECORDS_PATH, TFRECORDS_TARBALL)\n",
    "print (s3_tfrecords)\n",
    "! aws s3 cp $s3_tfrecords code/tfrecords  \n",
    "\n",
    "# tarball is now in code/tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 23272796\r\n",
      "-rw-r--r-- 1 root   root   7764419626 Apr 26 18:43 20200425_tfrecords.tar.gz\r\n",
      "-rw-r--r-- 1 root   root      3340715 Apr 26 21:24 20200426_annotation.tar.gz\r\n",
      "-rw-r--r-- 1 root   root   7824595037 Apr 26 21:24 20200426_jpeg_images.tar.gz\r\n",
      "-rw-r--r-- 1 root   root   7840680784 Apr 26 21:18 20200426_tfrecords.tar.gz\r\n",
      "drwx------ 2 root   root        16384 Apr 25 17:38 lost+found\r\n",
      "-rw-r--r-- 1 jayson jayson  398262635 Apr 25 17:12 snapshot_20200425b_8100.tar.gz\r\n",
      "drwxrwxrwx 5 root   root         4096 Apr 26 17:45 tfrecord\r\n"
     ]
    }
   ],
   "source": [
    "# Option 2 - from ssd-usb0 (sneaker net)\n",
    "! ls /media/$USER/ssd-usb0/ -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200426_tfrecords.tar.gz\n",
      "/media/train/ssd-usb0/20200426_tfrecords.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "print (TFRECORDS_TARBALL)\n",
    "! ls /media/$USER/ssd-usb0/$TFRECORDS_TARBALL\n",
    "! cp /media/$USER/ssd-usb0/$TFRECORDS_TARBALL code/tfrecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regardless - process the tarball\n",
    "pick up here - regardless of what option you chose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "media/home/jay/projects/camera-api/20200426_tfrecords/train.record-00001-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/val.record-00008-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/val.record-00009-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/val.record-00000-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/test.record-00005-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/test.record-00010-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/train.record-00008-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/val.record-00005-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/test.record-00002-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/test.record-00012-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/train.record-00015-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/test.record-00009-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/train.record-00004-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/test.record-00013-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/train.record-00012-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/val.record-00004-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/test.record-00001-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/train.record-00011-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/train.record-00002-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/val.record-00013-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/train.record-00003-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/train.record-00014-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/val.record-00006-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/val.record-00007-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/val.record-00001-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/test.record-00000-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/test.record-00006-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/train.record-00000-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/val.record-00010-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/train.record-00009-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/train.record-00005-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/train.record-00010-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/train.record-00013-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/val.record-00002-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/val.record-00003-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/test.record-00007-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/val.record-00012-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/train.record-00007-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/test.record-00015-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/test.record-00014-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/test.record-00003-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/test.record-00004-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/val.record-00011-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/train.record-00006-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/test.record-00008-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/val.record-00014-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/test.record-00011-of-00016\n",
      "media/home/jay/projects/camera-api/20200426_tfrecords/val.record-00015-of-00016\n",
      "/home/train/projects/ssd-dag\n"
     ]
    }
   ],
   "source": [
    "! tar -xvf code/tfrecords/$TFRECORDS_TARBALL --strip=6 -C code/tfrecords/tarball_extract\n",
    "\n",
    "# tfrecords are all in the tfrecords/ directory\n",
    "# SageMaker likes train/test subdirectories\n",
    "# - warning - confusion with 'test' vs 'eval'\n",
    "#      I feel eval is the post train loop to evaluate the training loop - thus called val(uaion)\n",
    "#         and test is to test a model with random real-world data\n",
    "#      SageMaker calls what I call val == test\n",
    "! pwd\n",
    "! rm code/tfrecords/train/*.*record* -f\n",
    "! rm code/tfrecords/val/*.*record*   -f\n",
    "! rm code/tfrecords/test/*.*record* -f\n",
    "\n",
    "! mv code/tfrecords/tarball_extract/train*.* code/tfrecords/train\n",
    "! mv code/tfrecords/tarball_extract/val*.* code/tfrecords/val\n",
    "! mv code/tfrecords/tarball_extract/test*.* code/tfrecords/test\n",
    "\n",
    "# ! rm code/tfrecords/$TFRECORDS_TARBALL\n",
    "\n",
    "# tarball is gone, tfrecord files are in code/tfrecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Model - 1x only\n",
    "\n",
    "You only have to pull the model once.  This exercise will RETRAIN an existing model.  So, you need the starting point.  In this example, we are training on top of the BASE == MobileNet V1 that was trained with COCO images.   You could train on top of a CFA model - just make sure you config everything properly.\n",
    "\n",
    "Copy the model from S3.    You are coping a model from an S3 folder.  There may be a label map and config file - that would make sense so you can reproduce that model.   However, if you are training on top of this model - those files aren't useful - MAKE SURE YOU UNDERSTAND THIS.   \n",
    "\n",
    "So when you pull the model from the folder - just make sure you understand if you are re-using those meta files (e.g. reproducing a model) or or if you need something new (xfer learning).  The training process will NOT read from this download.  The training program will read the config from the code/ just to help avoid this confusion.\n",
    "\n",
    "#### CKPT\n",
    "When you retrain, the config file has a train_config / fine_tune_checkpoint attribute.  You are going to download this BASE model and put it in the code/ckpt/ directory.   The training job will start with the checkpoint file you specify.   For example:\n",
    "\n",
    "fine_tune_checkpoint: \"ckpt/model.ckpt\"\n",
    "\n",
    "#### WARNING code/ckpt/checkpoints\n",
    "When you run training, it will checkpoint to code/ckpt/checkpoints.  \n",
    "- if you train for 5000 steps, then repeat, it will do nothing basically because it will just reload the 5000 checkpoint file.\n",
    "- then you'll think you're smart and you'll remove the 5000 checkpoint file.  Not so fast bucko!\n",
    "- because then you'll discover  there is some pointer in the checkpoints/ that told the system the 5000 checkpoint exists - but now it doesn't because you just wiped it - so you'll get an error (that's difficult to figure out)\n",
    "\n",
    "just delete the checkpoints directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Physical or Docker\n",
    "# - you may have to delete stuff first\n",
    "# $ cd code\n",
    "# $ rm -rf models\n",
    "\n",
    "# $ cd ../tasks\n",
    "# $ bash install_tf_models.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMaker (& Local?)\n",
    "# -- warning - something not right here\n",
    "#    I think you have to do this local or SageMaker (gotta have a base model)\n",
    "s3_model_folder = os.path.join(S3_MODEL_PATH, BASE_MODEL_FOLDER)\n",
    "! aws s3 cp $s3_model_folder code/ckpt --recursive\n",
    "\n",
    "# code/ckpt now has model.ckpt.* files\n",
    "# there is also a pipeline.config file (this one was configured for the Google Coral - you don't want it)\n",
    "# there are also some tflite files - we don't want them either"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### github tensorflow/models - 1x Only\n",
    "manually git clone the FIRST TIME.   The official TensorFlow github repo has a related repo with a bunch of models, tutorials, utilities etc.   We are using them.  So clone them to this machine.   In a subsequent step, we'll get the files we need from this local copy.\n",
    "\n",
    "!! - hold it -  \n",
    "!! this doesn't make sense, try not doing this - I don't think you need to git clone  \n",
    "!! doesn't the install_tf_models.sh do all of this?  \n",
    "!! I think we no longer copy, set just clone to code/models\n",
    "!! thus, you don't need this manual git clone, just run install_tf_models.sh in the next cell\n",
    "\n",
    "\n",
    "PHYSICAL COMPUTER  \n",
    "`cd ~/projects`  \n",
    "SAGEMAKER  \n",
    "`you should be in the SageMaker directory`  \n",
    "\n",
    "#### this will put /models into ~/projects  (you'll have ~/projects/models)\n",
    "`git clone https://github.com/tensorflow/models.git`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 time only\n",
    "\n",
    "# get the latest software\n",
    "# - git clone (to <project>/code/models)\n",
    "# - get the protobuf compiler\n",
    "# - compile the protobufs\n",
    "# - clean up\n",
    "os.chdir(TASKS)\n",
    "! ./install_tf_models.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local (Script) Mode Training\n",
    "\n",
    "#### -> if you know what you're doing, (you have a working SageMaker HOSTED training job) - you can jump out here!\n",
    "\n",
    "see the AWS SageMaker tutorials notably:  \n",
    "https://github.com/aws-samples/amazon-sagemaker-script-mode/blob/master/tf-eager-script-mode/tf-eager-sm-scriptmode.ipynb\n",
    "\n",
    "The point here is, you can develop a training script locally, then know (have a high degree of confidence) it will run as a SageMaker training job.   (This is relatively new, the old way was more difficult and cumbersome.)\n",
    "\n",
    "### What is Local?\n",
    "- local on THIS SageMaker Notebook (EC2) server\n",
    "  - p2.xlarge - no problem\n",
    "  - t2.medium - probably not (I think this is the same footprint as the feeble Workspace)\n",
    "- A desktop computer.\n",
    "  - works great on an Ubuntu laptop with GPU\n",
    "  - should work on a Windows laptop if you have a python environment set up\n",
    "- An AWS Workspace - not enough memory, you'll get a memory error.   The code runs - but fails on a memory allocation error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do you have a training script that will run locally - without Docker?\n",
    "\n",
    "considering what is coming up, you want all code needed to train in one directory. (in this example, that will be the code/ directory.) That directory will be included in the Docker image.    \n",
    "\n",
    "This is going to get a little more cumbersome because we took a bunch of stuff from the (official) github tensorflow/models project.   - we are using the MobileNet model and a BUNCH of utilities.    To make sure we keep up to date, we will get all of this programmatically - i.e. clone the most recent version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training Configuration\n",
    "\n",
    "trained-models/ may have a config file and a label map in the directories.  You can start with one of these.  BUT - there may be environmental variable values that you don't want - and you don't want the s3 pull operation to keep overwriting your config.   So, you can pull a model from s3.  Review the .config and label map files BUT !!! put YOUR config & label map file in the code/ directory.\n",
    "\n",
    "#### .config file\n",
    "See the config file for all parameters. the IN USE .config file is in the code/ direcory But you DEFINITELY need to look at these!\n",
    "- num_classes = should be consistent with labels.txt & label map\n",
    "- label_map_path (train & eval)\n",
    "    - there may be one in the model/ (that you pulled from s3)\n",
    "    - but move your desired label map to code/\n",
    "- inputs (train & eval) - not sure, SageMaker is passing that in\n",
    "- check all of the path statements \n",
    "- fine_tune_checkpoint - make sure you are fine tuning the correct file\n",
    "    - don't cross a _v1 with a _v2 - that definitely work\n",
    "   \n",
    "#### label map .pbtxt\n",
    "- classes start with 1 (not 0 based)\n",
    "- make sure your label map class count matches the config file\n",
    "- and it should match the label \n",
    "\n",
    "#### NOTE - a missing file will generate a complex error message.  NOT something as simple as file not found. \n",
    "\n",
    "#### NOTE - --model_dir parameter: \n",
    "- local mode, it needs to be model\n",
    "- SageMaker HOST mode, it needs to be /opt/ml/model\n",
    "\n",
    "--num_train_steps  \n",
    "   500 very quick test  \n",
    "   5000 more like it  \n",
    "-- num_eval_steps  \n",
    "   10 verify quick test  \n",
    "   100 more like it\n",
    "   \n",
    "beware of batch size - if you run out of GPU memory - see the config file, batch_size: 32;  you may need to decrease it if you have a small GPU\n",
    "\n",
    "GPU should be 95% utilized.  \n",
    "`nvidia-smi -l 1`\n",
    "CPU will be about 30%  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(CODE)   # this will be the training directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r model\n",
    "! mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! Warning !!!\n",
    "# I changed the pipeline_config_path = local*.config\n",
    "# this local version expects the data to be in code/tfrecords\n",
    "\n",
    "# sagemaker*.config\n",
    "#  uses S3 to move the data\n",
    "\n",
    "# !!! I haven't tested !!!\n",
    "\n",
    "# 20200122 - physical computer (Inspiron)\n",
    "#  using Jupyter (below) error: ModuleNotFoundError: No module named 'absl'\n",
    "#  but, ran fine from terminal\n",
    "#\n",
    "#  nvidia-smi\n",
    "#      NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. \n",
    "#      Make sure that the latest NVIDIA driver is installed and running.\n",
    "#  but it ran trained fine so CUDA was good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> installing: cython\n",
      "Requirement already satisfied: cython in /home/train/anaconda3/envs/tf115/lib/python3.7/site-packages (0.29.17)\n",
      "--> installing: pycocotools\n",
      "Requirement already satisfied: pycocotools in /home/train/anaconda3/envs/tf115/lib/python3.7/site-packages (2.0.0)\n",
      "--> installing: matplotlib\n",
      "Requirement already satisfied: matplotlib in /home/train/anaconda3/envs/tf115/lib/python3.7/site-packages (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/train/anaconda3/envs/tf115/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/train/anaconda3/envs/tf115/lib/python3.7/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/train/anaconda3/envs/tf115/lib/python3.7/site-packages (from matplotlib) (1.18.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/train/anaconda3/envs/tf115/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/train/anaconda3/envs/tf115/lib/python3.7/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/train/anaconda3/envs/tf115/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.14.0)\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "*** train.py/main()\n",
      "*** FLAGS ***\n",
      "pipeline_config_path: local_mobilenet_v1_ssd_security_scratch_v6.config\n",
      "config exists: True\n",
      "file: display.py\n",
      "file: security_label_map.pbtxt\n",
      "file: __pycache__\n",
      "file: utils\n",
      "file: ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config\n",
      "file: local_mobilenet_v1_ssd_security_scratch_v2.config\n",
      "file: ssd_mobilenet_v1_focal_loss_pets.config\n",
      "file: requirements.txt\n",
      "file: tflite_interpreter.py\n",
      "file: local_mobilenet_v1_ssd_security_scratch_v5.config\n",
      "file: local_mobilenet_v1_ssd_security_scratch_v1.config\n",
      "file: ssd_mobilenet_v1_300x300_coco14_sync.config\n",
      "file: embedded_ssd_mobilenet_v1_coco.config\n",
      "file: tf_serving_inference.py\n",
      "file: ssd_mobilenet_v1_pets.config\n",
      "file: local_mobilenet_v1_ssd_security_scratch_v6.config\n",
      "file: cfa_utils\n",
      "file: detect.py\n",
      "file: ssd_mobilenet_v1_quantized_300x300_coco14_sync.config\n",
      "file: ckpt\n",
      "file: ssd_mobilenet_v1_focal_loss_pets_inference.config\n",
      "file: cfa_prod_label_map.pbtxt\n",
      "file: train115.py\n",
      "file: annotation.py\n",
      "file: __init__.py\n",
      "file: local_mobilenet_v1_ssd_retrain.config\n",
      "file: ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync.config\n",
      "file: local_mobilenet_v1_ssd_security_scratch_v3.config\n",
      "file: ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config\n",
      "file: model\n",
      "file: mscoco_label_map.pbtxt\n",
      "file: tfrecords\n",
      "file: sagemaker_mobilenet_v1_ssd_retrain.config\n",
      "file: object_detection\n",
      "file: local_mobilenet_v1_ssd_coco.config\n",
      "file: ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync.config\n",
      "file: ssd_mobilenet_v1_coco.config\n",
      "file: models\n",
      "file: ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync.config\n",
      "file: local_mobilenet_v1_ssd_security_scratch_v4.config\n",
      "file: ssdlite_mobilenet_v1_coco.config\n",
      "file: pipeline.config\n",
      "file: train.py\n",
      "file: local_mobilenet_v1_ssd_security_retrain.config\n",
      "model_dir: model\n",
      "train: tfrecords/train/train.*\n",
      "val: tfrecords/val/val.*\n",
      "sample_1_of_n_eval_examples: 1\n",
      "hparams_overrides: None\n",
      "checkpoint_dir: None\n",
      "WARNING:tensorflow:From /home/train/projects/ssd-dag/code/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "W0426 21:39:06.863731 140173052229440 module_wrapper.py:139] From /home/train/projects/ssd-dag/code/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "checking inputs for: train_input_config\n",
      "path: False tfrecords/train/train.*\n",
      "checking inputs for: eval_input_config\n",
      "path: False tfrecords/val/val.*\n",
      " - - - - - - - - -\n",
      "- creating Estimator -\n",
      "checkpoint_dir: None\n",
      "- creating train_spec & eval_spec\n",
      "- train & evaluate\n",
      "- IF YOU GET NOTHING AFTER THIS, verify num_training_steps > largest checkpoint in /model\n",
      "2020-04-26 21:39:31.673193: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-04-26 21:39:31.864237: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz\n",
      "2020-04-26 21:39:31.872941: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b2b3bdc9c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-26 21:39:31.873011: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-04-26 21:39:31.891292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-04-26 21:39:32.024690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-26 21:39:32.025013: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b2b3bdc690 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-04-26 21:39:32.025023: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2020-04-26 21:39:32.031365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-26 21:39:32.031629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.635\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-04-26 21:39:32.033492: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-04-26 21:39:32.050328: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-04-26 21:39:32.058531: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-04-26 21:39:32.061336: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-04-26 21:39:32.080474: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-04-26 21:39:32.092806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-04-26 21:39:32.141467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-04-26 21:39:32.141718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-26 21:39:32.143338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-26 21:39:32.144796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2020-04-26 21:39:32.155427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-04-26 21:39:32.158773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-04-26 21:39:32.158834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2020-04-26 21:39:32.158857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2020-04-26 21:39:32.165997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-26 21:39:32.167652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-26 21:39:32.169210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10065 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-26 21:40:07.219516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-04-26 21:40:08.398668: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-04-26 21:50:03.942433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-26 21:50:03.942618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.635\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-04-26 21:50:03.942647: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-04-26 21:50:03.942656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-04-26 21:50:03.942665: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-04-26 21:50:03.942674: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-04-26 21:50:03.942682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-04-26 21:50:03.942691: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-04-26 21:50:03.942699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-04-26 21:50:03.942731: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-26 21:50:03.942892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-26 21:50:03.943030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2020-04-26 21:50:03.943048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-04-26 21:50:03.943053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2020-04-26 21:50:03.943057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2020-04-26 21:50:03.943100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-26 21:50:03.943263: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-04-26 21:50:03.943420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10065 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "creating index...\n",
      "index created!\n",
      "creating index...\n",
      "index created!\n",
      "2020-04-26 21:57:22.752572: W tensorflow/core/framework/op_kernel.cc:1639] Invalid argument: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/numpy/core/function_base.py\", line 117, in linspace\n",
      "    num = operator.index(num)\n",
      "\n",
      "TypeError: 'numpy.float64' object cannot be interpreted as an integer\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/train/projects/ssd-dag/code/object_detection/metrics/coco_evaluation.py\", line 384, in first_value_func\n",
      "    self._metrics = self.evaluate()\n",
      "\n",
      "  File \"/home/train/projects/ssd-dag/code/object_detection/metrics/coco_evaluation.py\", line 215, in evaluate\n",
      "    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n",
      "\n",
      "  File \"/home/train/projects/ssd-dag/code/object_detection/metrics/coco_tools.py\", line 176, in __init__\n",
      "    iouType=iou_type)\n",
      "\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/pycocotools/cocoeval.py\", line 76, in __init__\n",
      "    self.params = Params(iouType=iouType) # parameters\n",
      "\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/pycocotools/cocoeval.py\", line 527, in __init__\n",
      "    self.setDetParams()\n",
      "\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n",
      "    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n",
      "\n",
      "  File \"<__array_function__ internals>\", line 6, in linspace\n",
      "\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/numpy/core/function_base.py\", line 121, in linspace\n",
      "    .format(type(num)))\n",
      "\n",
      "TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
      "    target_list, run_metadata)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.OutOfRangeError: 2 root error(s) found.\n",
      "  (0) Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/Shape_180/_3307]]\n",
      "  (1) Out of range: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "0 successful operations.\n",
      "0 derived errors ignored.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/evaluation.py\", line 272, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1360, in run\n",
      "    raise six.reraise(*original_exc_info)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1418, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1176, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.OutOfRangeError: 2 root error(s) found.\n",
      "  (0) Out of range: End of sequence\n",
      "\t [[node IteratorGetNext (defined at /home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n",
      "\t [[Postprocessor/BatchMultiClassNonMaxSuppression/MultiClassNonMaxSuppression/Shape_180/_3307]]\n",
      "  (1) Out of range: End of sequence\n",
      "\t [[node IteratorGetNext (defined at /home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n",
      "0 successful operations.\n",
      "0 derived errors ignored.\n",
      "\n",
      "Original stack trace for 'IteratorGetNext':\n",
      "  File \"train115.py\", line 188, in <module>\n",
      "    tf.compat.v1.app.run()\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/absl/app.py\", line 299, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"train115.py\", line 181, in main\n",
      "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n",
      "    return self.run_local()\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1426, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 594, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 619, in _save\n",
      "    if l.after_save(session, step):\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 519, in after_save\n",
      "    self._evaluate(global_step_value)  # updates self.eval_result\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 539, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 920, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 480, in evaluate\n",
      "    name=name)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 522, in _actual_eval\n",
      "    return _evaluate()\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 504, in _evaluate\n",
      "    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1511, in _evaluate_build_graph\n",
      "    self._call_model_fn_eval(input_fn, self.config))\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1544, in _call_model_fn_eval\n",
      "    input_fn, ModeKeys.EVAL)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1025, in _get_features_and_labels_from_input_fn\n",
      "    self._call_input_fn(input_fn, mode))\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/util.py\", line 65, in parse_input_fn_result\n",
      "    result = iterator.get_next()\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\", line 426, in get_next\n",
      "    name=name)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\", line 2518, in iterator_get_next\n",
      "    output_shapes=output_shapes, name=name)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n",
      "    attrs, op_def, compute_device)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
      "    target_list, run_metadata)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/numpy/core/function_base.py\", line 117, in linspace\n",
      "    num = operator.index(num)\n",
      "\n",
      "TypeError: 'numpy.float64' object cannot be interpreted as an integer\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/train/projects/ssd-dag/code/object_detection/metrics/coco_evaluation.py\", line 384, in first_value_func\n",
      "    self._metrics = self.evaluate()\n",
      "\n",
      "  File \"/home/train/projects/ssd-dag/code/object_detection/metrics/coco_evaluation.py\", line 215, in evaluate\n",
      "    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n",
      "\n",
      "  File \"/home/train/projects/ssd-dag/code/object_detection/metrics/coco_tools.py\", line 176, in __init__\n",
      "    iouType=iou_type)\n",
      "\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/pycocotools/cocoeval.py\", line 76, in __init__\n",
      "    self.params = Params(iouType=iouType) # parameters\n",
      "\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/pycocotools/cocoeval.py\", line 527, in __init__\n",
      "    self.setDetParams()\n",
      "\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n",
      "    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n",
      "\n",
      "  File \"<__array_function__ internals>\", line 6, in linspace\n",
      "\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/numpy/core/function_base.py\", line 121, in linspace\n",
      "    .format(type(num)))\n",
      "\n",
      "TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc_3}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"train115.py\", line 188, in <module>\n",
      "    tf.compat.v1.app.run()\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/absl/app.py\", line 299, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"train115.py\", line 181, in main\n",
      "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n",
      "    return self.run_local()\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1360, in run\n",
      "    raise six.reraise(*original_exc_info)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1426, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 594, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 619, in _save\n",
      "    if l.after_save(session, step):\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 519, in after_save\n",
      "    self._evaluate(global_step_value)  # updates self.eval_result\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 539, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 920, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 480, in evaluate\n",
      "    name=name)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 522, in _actual_eval\n",
      "    return _evaluate()\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 511, in _evaluate\n",
      "    output_dir=self.eval_dir(name))\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1619, in _evaluate_run\n",
      "    config=self._session_config)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/evaluation.py\", line 272, in _evaluate_once\n",
      "    session.run(eval_ops, feed_dict)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 861, in __exit__\n",
      "    self._close_internal(exception_type)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 894, in _close_internal\n",
      "    h.end(self._coordinated_creator.tf_sess)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 951, in end\n",
      "    self._final_ops, feed_dict=self._final_ops_feed_dict)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.InvalidArgumentError: TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/numpy/core/function_base.py\", line 117, in linspace\n",
      "    num = operator.index(num)\n",
      "\n",
      "TypeError: 'numpy.float64' object cannot be interpreted as an integer\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 235, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/train/projects/ssd-dag/code/object_detection/metrics/coco_evaluation.py\", line 384, in first_value_func\n",
      "    self._metrics = self.evaluate()\n",
      "\n",
      "  File \"/home/train/projects/ssd-dag/code/object_detection/metrics/coco_evaluation.py\", line 215, in evaluate\n",
      "    coco_wrapped_groundtruth, coco_wrapped_detections, agnostic_mode=False)\n",
      "\n",
      "  File \"/home/train/projects/ssd-dag/code/object_detection/metrics/coco_tools.py\", line 176, in __init__\n",
      "    iouType=iou_type)\n",
      "\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/pycocotools/cocoeval.py\", line 76, in __init__\n",
      "    self.params = Params(iouType=iouType) # parameters\n",
      "\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/pycocotools/cocoeval.py\", line 527, in __init__\n",
      "    self.setDetParams()\n",
      "\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/pycocotools/cocoeval.py\", line 507, in setDetParams\n",
      "    self.iouThrs = np.linspace(.5, 0.95, np.round((0.95 - .5) / .05) + 1, endpoint=True)\n",
      "\n",
      "  File \"<__array_function__ internals>\", line 6, in linspace\n",
      "\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/numpy/core/function_base.py\", line 121, in linspace\n",
      "    .format(type(num)))\n",
      "\n",
      "TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "\n",
      "\n",
      "\t [[node PyFunc_3 (defined at /home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n",
      "\n",
      "Original stack trace for 'PyFunc_3':\n",
      "  File \"train115.py\", line 188, in <module>\n",
      "    tf.compat.v1.app.run()\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/absl/app.py\", line 299, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"train115.py\", line 181, in main\n",
      "    tf.estimator.train_and_evaluate(estimator, train_spec, eval_specs[0])\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\n",
      "    return self.run_local()\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n",
      "    run_metadata=run_metadata)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n",
      "    return self._sess.run(*args, **kwargs)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/monitored_session.py\", line 1426, in run\n",
      "    run_metadata=run_metadata))\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 594, in after_run\n",
      "    if self._save(run_context.session, global_step):\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/training/basic_session_run_hooks.py\", line 619, in _save\n",
      "    if l.after_save(session, step):\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 519, in after_save\n",
      "    self._evaluate(global_step_value)  # updates self.eval_result\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 539, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/training.py\", line 920, in evaluate_and_export\n",
      "    hooks=self._eval_spec.hooks)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 480, in evaluate\n",
      "    name=name)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 522, in _actual_eval\n",
      "    return _evaluate()\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 504, in _evaluate\n",
      "    self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1511, in _evaluate_build_graph\n",
      "    self._call_model_fn_eval(input_fn, self.config))\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1547, in _call_model_fn_eval\n",
      "    features, labels, ModeKeys.EVAL, config)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1149, in _call_model_fn\n",
      "    model_fn_results = self._model_fn(features=features, **kwargs)\n",
      "  File \"/home/train/projects/ssd-dag/code/object_detection/model_lib.py\", line 470, in model_fn\n",
      "    eval_config, list(category_index.values()), eval_dict)\n",
      "  File \"/home/train/projects/ssd-dag/code/object_detection/eval_util.py\", line 927, in get_eval_metric_ops_for_evaluators\n",
      "    eval_dict))\n",
      "  File \"/home/train/projects/ssd-dag/code/object_detection/metrics/coco_evaluation.py\", line 394, in get_estimator_eval_metric_ops\n",
      "    first_value_op = tf.py_func(first_value_func, [], tf.float32)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 513, in py_func\n",
      "    return py_func_common(func, inp, Tout, stateful, name=name)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 495, in py_func_common\n",
      "    func=func, inp=inp, Tout=Tout, stateful=stateful, eager=False, name=name)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 318, in _internal_py_func\n",
      "    input=inp, token=token, Tout=Tout, name=name)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_script_ops.py\", line 170, in py_func\n",
      "    \"PyFunc\", input=input, token=token, Tout=Tout, name=name)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n",
      "    attrs, op_def, compute_device)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n",
      "    op_def=op_def)\n",
      "  File \"/home/train/anaconda3/envs/tf115/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# These parameters can be set, if ommitted, takes values from SM_CHANNEL_ {_MODEL_DIR, _TRAIN, _VAL}\n",
    "# --model_dir\n",
    "# --train\n",
    "# --val\n",
    "# note the config file\n",
    "\n",
    "! python train115.py \\\n",
    "  --pipeline_config_path=\"local_mobilenet_v1_ssd_security_scratch_v6.config\" \\\n",
    "  --num_train_steps=\"100000\" \\\n",
    "  --num_eval_steps=\"17500\"  \\\n",
    "  --model_dir='model' \\\n",
    "  --train='tfrecords/train/train.*' \\\n",
    "  --val='tfrecords/val/val.*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n",
    "\n",
    "`ssh -L 8010:localhost:6006 train@192.168.1.120`  \n",
    "`conda activate tf115`  \n",
    "`cd projects/ssd-dag/code`  \n",
    "`tensorboard --logdir==./model`  \n",
    "`localhost:8010`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trained Model Output -- IMPORTANT\n",
    "Where did it go? - THERE IS A BIG DIFFERENCE BETWEEN LOCAL TRAIN AND HOSTED TRAIN -- important !!\n",
    "\n",
    "train*.py will put the output in code/model    This is true for local or SageMaker hosted trained.   In this case, you trained locally, so the output is in code/model  -- end of story.\n",
    "\n",
    "\n",
    "When you train with a SageMaker Hosted train, the output still goes to code/model -- HOWEVER - that is in a docker image (that you will never see).  Then it gets coped to S3.   Then the notebook (TrainModel_Step3_TrainingJob) pulls a model output from S3.   Then extracts the tarball to {PROJECT}/trained_model   SO AT THIS POINT THE OUTPUT IS IN A DIFFERENT LOCATION !!\n",
    "\n",
    "The convert graph script is pulling from {PROJECT}/trained_model (not the native code/model location).    The easiest solution (you will see below) is to copy the desired checkpoint graph to the {PROJECT}/trained_model location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(CODE)   # this will be the training directory\n",
    "! ls -la  {MODEL_OUTPUT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "1. if you run for 500 steps, then rerun the exact process, it is going to restore /ckpt/checkpoints (ckpt-500) and then thinks it is done.  So, basically does nothing\n",
    "2. Don't delete ckpt/  (rm ckpt/*.*) WITHOUT removing ckpt/checkpoints/   The program is always checking that checkpoints subdirectory and trying to restore.  For exampmle, you delete ckpt/ but leave ckpt/checkpoints, it finds a reference to ckpt-500 but you just deleted it - so it aborts\n",
    "3. Always check your files & paths carefully - the error messages that get thrown with a missing file are not always clear - and my send you on a wild goose chase when in reality - it was just a missing file\n",
    "4. can't import nets - this is a PATH problem (models/research/slim needs to be in your path) - in the train.py program, it's programmatically added\n",
    "5. OOM when allocating tensor of shape [32,19,19,512] and type float\n",
    "\t [[{{node gradients/zeros_97}}]] -- go to the config file and change batch size to be smaller (e.g. 16)\n",
    "6. AttributeError: 'ParallelInterleaveDataset' object has no attribute '_flat_structure --- check your directories, like something didn't get installed correction (base model?  models/research stuff?  training data) -- seems to be a problem with the TF build from scratch;   use a pip install and this went away\n",
    "7. if you are mixing local ops and Docker runs - you may have messed up the ownership file outputs and checkpoints - try deleting everything and a new pull\n",
    "8. trains - then error:  TypeError: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a useable model\n",
    "At this point you have checkpoint files.   You need models (graphs).   There are many flavors:\n",
    "    - saved graph\n",
    "    - frozen graph\n",
    "    - TensorFlow Lite\n",
    "    - TensorRT\n",
    "    - EdgeTPU\n",
    "    \n",
    "The notebook:  TrainingJob_Step3_TrainingJob will show you how to convert a checkpoint file to a graph (frozen graph & tflite).   There is a bash file to do this.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WAKE UP - make sure NUM_TRAINING_STEPS = the max number in the checkpoint files you listed above\n",
    "#  e.g. \n",
    "# ls model\n",
    "# -rw-rw-r--  1 ec2-user ec2-user 41116528 Jan 28 15:16 model.ckpt-6000.data-00000-of-00001\n",
    "# -rw-rw-r--  1 ec2-user ec2-user    27275 Jan 28 15:16 model.ckpt-6000.index\n",
    "# -rw-rw-r--  1 ec2-user {ec2-user  6987305 Jan 28 15:16 model.ckpt-6000.meta\n",
    "NUM_TRAINING_STEPS = 219267\n",
    "! cp {CODE}/model/*{NUM_TRAINING_STEPS}* {PROJECT}/trained_model\n",
    "! ls {PROJECT}/trained_model/*{NUM_TRAINING_STEPS}*\n",
    "\n",
    "# get the config from the train*.py parameters above\n",
    "PIPELINE_CONFIG = 'local_mobilenet_v1_ssd_security_retrain.config'\n",
    "# PIPELINE_CONFIG = 'local_mobilenet_v1_ssd_retrain.config'\n",
    "! ls {CODE}/{PIPELINE_CONFIG}\n",
    "\n",
    "# if you don't see your checkpoint in */trained_model/  STOP - and fix it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert checkpoint is a task script - located in the tasks/ directory\n",
    "os.chdir(TASKS)  \n",
    "! ./convert_checkpoint_to_edgetpu_tflite.sh --checkpoint_num {NUM_TRAINING_STEPS} --pipeline_config {PIPELINE_CONFIG}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow FROZEN GRAPH\n",
    "! ls {PROJECT}/tensorflow_model -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow Lite model\n",
    "! ls {PROJECT}/tflite_model -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Security\n",
    "If you are working on the security project,   you need to:  \n",
    "put thye output_tflight_graph.tflite file in:  camera-api/model/  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the tflite model over to camera-api/model\n",
    "! cp  {PROJECT}/tflite_model/output_tflite_graph.tflite {CAMERA_API_MODEL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just checking ...\n",
    "! ls -ls {CODE}/ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move the (converted?  frozen?) ckpt to the starting point\n",
    "# NOW you can re-train on top of it\n",
    "! cp {PROJECT}/tensorflow_model/model.ckpt.* {CODE}/ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup\n",
    "! aws s3 ls --profile=jmduff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_parameter = '*{}*'.format(NUM_TRAINING_STEPS)\n",
    "! ls {MODEL_OUTPUT}/{include_parameter}\n",
    "! aws s3 cp {MODEL_OUTPUT} s3://jmduff.security-system/model/{MODEL_DATE}/ --exclude='*.*' --include={include_parameter} --recursive --profile=jmduff\n",
    "! aws s3 cp {PROJECT}/tensorflow_model s3://jmduff.security-system/model/{MODEL_DATE}/ --exclude='*.*' --include='*.*' --recursive --profile=jmduff\n",
    "! aws s3 cp {PROJECT}/tflite_model s3://jmduff.security-system/model/{MODEL_DATE}/ --exclude='*.*' --include='*.*' --recursive --profile=jmduff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/media/home/jay/projects/ssd-dag')\n",
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
