{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make TFRecords from VOC XML & jpgs\n",
    "\n",
    "THIS IS REDUNDANTE with UnderstandingObjectDetectionExample  \n",
    "Use the other notebook for a full understanding\n",
    "\n",
    "## Prerequitistes\n",
    "### Input\n",
    "1. you have jpeg images\n",
    "2. you have annotations - XML format, VOC Pascal format standard\n",
    "\n",
    "### Output\n",
    "tfrecords_dir needs to have 3 subdirectories\n",
    "/train\n",
    "/val\n",
    "/test\n",
    "\n",
    "this code leverages the standards and templates as much as possible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# This is needed since we cloned tensorflow/models under code.\n",
    "# - if you don't know what this means\n",
    "#   Look at the notebook TrainModel_Step1_Local\n",
    "#      in this notebook, you basically set up the project with includes cloning \n",
    "#      and compiling the tensorflow/models repo\n",
    "#   we are using the utilities found in that repo\n",
    "\n",
    "cwd = os.getcwd()\n",
    "models = os.path.join(cwd, 'code/models/research/')\n",
    "slim = os.path.join(cwd, 'code/models/research/slim')\n",
    "sys.path.append(models)\n",
    "sys.path.append(slim)\n",
    "\n",
    "from object_detection.utils import ops as utils_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code.cfa_utils.example_utils import voc_to_tfrecord_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "# project directories\n",
    "PROJECT = os.getcwd()\n",
    "CODE = os.path.join(PROJECT, \"code\")\n",
    "DATA = os.path.join(PROJECT, \"data\")\n",
    "\n",
    "IMAGE_DIR = os.path.join(DATA, \"jpeg_images\")\n",
    "ANNOTATION_DIR = os.path.join(DATA, \"annotations\")\n",
    "LABEL_MAP_FILE = os.path.join(CODE, 'cfa_prod_label_map.pbtxt')\n",
    "TFRECORD_DIR = os.path.join(PROJECT, 'tmp')\n",
    "TRAINING_SPLIT_TUPLE =  (60,30,10)\n",
    "INCLUDE_CLASSES = 'all'\n",
    "EXCLUDE_TRUNCATED = False,\n",
    "EXCLUDE_DIFFICULT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to fix the labels\n",
    "# it's in the other notebook:  UnderstaningObjectDetectionExample\n",
    "# -- not finished - stopped here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_to_tfrecord_file(IMAGE_DIR,\n",
    "                    ANNOTATION_DIR,\n",
    "                    LABEL_MAP_FILE,\n",
    "                    TFRECORD_DIR,\n",
    "                    TRAINING_SPLIT_TUPLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
