{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding TensorRT - Convert Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the Model\n",
    "1. checkpoint -> Frozen TensorFlow graph  \n",
    "2. Frozen TensorFlow graph -> TFLite  \n",
    "3a. TFLite -> EdgeTPU (Google Coral)  \n",
    "3b. TFLite -> TensorRT (NVIDIA GPU)  \n",
    "\n",
    "### Did you train locally or via SageMaker Docker?\n",
    "- Locally - the training checkpoint is in code/model\n",
    "- SageMaker - the training checkpoint was pushed to S3 then pulled back down and extracted to /trained_model\n",
    "\n",
    "The conversion script expects it to be in /trained_model\n",
    "\n",
    "\n",
    "## CUDA / TensorFlow Versions\n",
    "### TF Lite\n",
    "No big deal and there are probably no concerns here\n",
    "\n",
    "### TensorRT 7.0\n",
    "TensorRT 7.0 says the model must be trained w/ TensorFlow 1.14 (which requires CUDA 10.0).  \n",
    "- did you train w/ 1.14  \n",
    "- did you convert to tflite w/ 1.14  \n",
    "\n",
    "just beware\n",
    "\n",
    "### Edge TPU (Google Coral)\n",
    "Hmm, this all worked with TF 1.13 and 1.14, haven't tested 1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLOBALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBALS so work with the bash scripts\n",
    "PROJECT_DIR = os.getcwd()\n",
    "TASKS_DIR = os.path.join(PROJECT_DIR, 'tasks')\n",
    "\n",
    "CODE_DIR = os.path.join(PROJECT_DIR, 'code')\n",
    "TFLITE_DIR = os.path.join(PROJECT_DIR, 'tflite_model')\n",
    "TENSORFLOW_DIR = os.path.join(PROJECT_DIR, 'tensorflow_model')\n",
    "MODEL_RESEARCH_DIR = os.path.join(PROJECT_DIR, 'code/models/research')\n",
    "SLIM_DIR = os.path.join(MODEL_RESEARCH_DIR, 'slim')\n",
    "TRAINED_DIR = os.path.join(PROJECT_DIR, 'trained_model')\n",
    "\n",
    "NUM_TRAINING_STEPS = 6000\n",
    "# Local (non-SageMaker) -or- SageMaker\n",
    "# PIPELINE_CONFIG = 'sagemaker_mobilenet_v1_ssd_retrain.config'\n",
    "PIPELINE_CONFIG = 'local_mobilenet_v1_ssd_retrain.config'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PICK 1 - A. Local or  B. Hosted\n",
    "\n",
    "## A - Locally Trained\n",
    "### get the checkpoint files to the correct location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is your checkpoint (NUM_TRAINING_STEPS) there?\n",
    "! ls {CODE_DIR}/model/*{NUM_TRAINING_STEPS}*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy to the /trained_model directory\n",
    "# this will make it compatible with the convert script\n",
    "! cp {CODE_DIR}/model/*{NUM_TRAINING_STEPS}* {TRAINED_DIR}\n",
    "! ls {TRAINED_DIR}/*{NUM_TRAINING_STEPS}* -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE_CONFIG = 'sagemaker_mobilenet_v1_ssd_retrain.config'\n",
    "PIPELINE_CONFIG = 'local_mobilenet_v1_ssd_retrain.config'\n",
    "\n",
    "# verify\n",
    "! ls {CODE_DIR}/{PIPELINE_CONFIG}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B - Trained in SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {TRAINED_DIR}/*{NUM_TRAINING_STEPS}* -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_CONFIG = 'sagemaker_mobilenet_v1_ssd_retrain.config'\n",
    "# PIPELINE_CONFIG = 'local_mobilenet_v1_ssd_retrain.config'\n",
    "\n",
    "# verify\n",
    "! ls {CODE_DIR}/{PIPELINE_CONFIG}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the Checkpoint to Frozen Graph & TF Lite Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert checkpoint is a task script - located in the tasks/ directory\n",
    "os.chdir(TASKS_DIR)  \n",
    "! ./convert_checkpoint_to_edgetpu_tflite.sh --checkpoint_num {NUM_TRAINING_STEPS} --pipeline_config {PIPELINE_CONFIG}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saved (output) Graphs\n",
    "\n",
    "These models will now behave differently.   The API is different and the performance is different.   Furthermore the dependencies are different.  The JSON that is returned will not be compatible.   So, make sure you know what your doing.\n",
    "\n",
    "### TensorFlow - Frozen Graph\n",
    "Look for examples of using a Tensor frozen graph.  Look at notebook:  DetectModel_Step1_Local_TensorFlowFrozenGraph\n",
    "\n",
    "### TensorFlow - TFLite\n",
    "Look for examples of using TensorFlow Lite.   Look at notebook: DetectMOdel_Step1_Local_TFLite\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {TENSORFLOW_DIR} -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {TFLITE_DIR} -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
